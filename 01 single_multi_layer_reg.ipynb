{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dhCWygD38aH4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.datasets import load_diabetes"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "diabetes = load_diabetes()"
      ],
      "metadata": {
        "id": "XicQaxXUw5gJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "diabetes;"
      ],
      "metadata": {
        "id": "sEzhQRjqxCO3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = diabetes.data, diabetes.target"
      ],
      "metadata": {
        "id": "Ez_262Z5xFju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cross validation\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y,\n",
        "                                                    test_size=0.2,\n",
        "                                                    random_state=42)"
      ],
      "metadata": {
        "id": "hu-2wwsIxxUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Scaling"
      ],
      "metadata": {
        "id": "3McQCjMx1414"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()"
      ],
      "metadata": {
        "id": "PZFIuzp5zVGw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_scaled = scaler.fit_transform(x_train)\n",
        "x_test_scaled = scaler.transform(x_test)"
      ],
      "metadata": {
        "id": "qRffKHIK1zCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.linear_model import Perceptron"
      ],
      "metadata": {
        "id": "AjhONGHG2SU2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "perceptron = Perceptron(max_iter=1000, random_state=42)"
      ],
      "metadata": {
        "id": "rFf3VqkD2yUJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "perceptron.fit(x_train_scaled, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "apAlY3kp3UuG",
        "outputId": "7c76f76a-5965-459a-fcf8-9b1f77b3b037"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Perceptron(random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Perceptron(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Perceptron</label><div class=\"sk-toggleable__content\"><pre>Perceptron(random_state=42)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# predict on test data"
      ],
      "metadata": {
        "id": "WSTXBvRh4hB7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = perceptron.predict(x_test_scaled)"
      ],
      "metadata": {
        "id": "poSdFVmw4ZEd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MSE = mean_squared_error(y_test, y_pred)"
      ],
      "metadata": {
        "id": "GhLEUrkI42RI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('mean squared error:', MSE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G54o_MNx5Jsa",
        "outputId": "ab4bbd4e-5f57-4974-8a09-25c146ca8154"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean squared error: 6050.932584269663\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(y_test, y_pred)\n",
        "\n",
        "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color = 'r')\n",
        "\n",
        "plt.xlabel('Actual')\n",
        "plt.ylabel('Predicted');"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "sZ3xvWY-5Nqp",
        "outputId": "6495131f-f6ca-48ac-8813-f461e7c642f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multi-Layer(sklearn)"
      ],
      "metadata": {
        "id": "wYVAWRGk8JrP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPRegressor"
      ],
      "metadata": {
        "id": "5sc-jdYC6Rw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlp = MLPRegressor(hidden_layer_sizes=(50, 50),\n",
        "                   activation= 'relu',\n",
        "                   max_iter=1000, random_state=42,\n",
        "                   solver = 'adam')"
      ],
      "metadata": {
        "id": "Gd6o09xA8Xbk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlp.fit(x_train_scaled, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "id": "PiREswBa8sEQ",
        "outputId": "b38a3d74-0613-47af-dc08-7ae6b7ecf395"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPRegressor(hidden_layer_sizes=(50, 50), max_iter=1000, random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPRegressor(hidden_layer_sizes=(50, 50), max_iter=1000, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(hidden_layer_sizes=(50, 50), max_iter=1000, random_state=42)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# predict on test set\n",
        "y_pred_mlp = mlp.predict(x_test_scaled)"
      ],
      "metadata": {
        "id": "bIE4_MwR9ENl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MSE_mlp = mean_squared_error(y_test, y_pred_mlp)"
      ],
      "metadata": {
        "id": "5mCW_SuG9Jrh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MSE_mlp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXGmJmEB9M_o",
        "outputId": "34aa7158-7acd-4666-df30-45a4c35e86de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2830.007843968821"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# single layer Keras"
      ],
      "metadata": {
        "id": "aFlD2FOO_yx1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "aWA21_689Si_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gjY2ql-HEZx",
        "outputId": "478708fa-7e36-474d-d73d-c0b1427ce084"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(353, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape[1:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFBc7d5aHeIy",
        "outputId": "aaa84af7-7f77-4658-9fc1-896d67680837"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10,)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_slp = Sequential()\n",
        "\n",
        "# add the layer\n",
        "model_slp.add(Dense(1, input_shape=x_train.shape[1:]))"
      ],
      "metadata": {
        "id": "20jx81wE_9od"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_slp.compile(optimizer='adam',\n",
        "              loss='mean_squared_error')"
      ],
      "metadata": {
        "id": "QOjG-kzHHrgm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_slp = model_slp.fit(x_train, y_train, epochs=1000, batch_size= 32,\n",
        "              validation_data=(x_test_scaled, y_test), verbose = 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2EiGLNGpISRh",
        "outputId": "2eeb1ad4-777d-4f2c-961b-0648d20fdb71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 26076.0508 - val_loss: 22832.0176\n",
            "Epoch 2/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 26072.5918 - val_loss: 22829.0273\n",
            "Epoch 3/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 26069.0703 - val_loss: 22825.7695\n",
            "Epoch 4/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 26065.4961 - val_loss: 22822.7930\n",
            "Epoch 5/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 26061.9824 - val_loss: 22820.1035\n",
            "Epoch 6/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 26058.6836 - val_loss: 22817.4922\n",
            "Epoch 7/1000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 26055.2090 - val_loss: 22815.0059\n",
            "Epoch 8/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 26051.5918 - val_loss: 22812.4668\n",
            "Epoch 9/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 26048.0957 - val_loss: 22809.9238\n",
            "Epoch 10/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 26044.6875 - val_loss: 22807.1387\n",
            "Epoch 11/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 26041.1328 - val_loss: 22804.2969\n",
            "Epoch 12/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 26037.5332 - val_loss: 22801.5918\n",
            "Epoch 13/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 26033.8301 - val_loss: 22799.1465\n",
            "Epoch 14/1000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 26030.2598 - val_loss: 22796.5098\n",
            "Epoch 15/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 26026.7812 - val_loss: 22793.7305\n",
            "Epoch 16/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 26023.3379 - val_loss: 22791.1016\n",
            "Epoch 17/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 26019.9805 - val_loss: 22788.3633\n",
            "Epoch 18/1000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 26016.4473 - val_loss: 22785.9512\n",
            "Epoch 19/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 26012.8730 - val_loss: 22783.3457\n",
            "Epoch 20/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 26009.4648 - val_loss: 22780.6523\n",
            "Epoch 21/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 26005.7910 - val_loss: 22777.9551\n",
            "Epoch 22/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 26002.1152 - val_loss: 22775.1953\n",
            "Epoch 23/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 25998.5742 - val_loss: 22772.5918\n",
            "Epoch 24/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 25995.1953 - val_loss: 22769.9551\n",
            "Epoch 25/1000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 25991.7754 - val_loss: 22766.9375\n",
            "Epoch 26/1000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 25988.2773 - val_loss: 22764.2129\n",
            "Epoch 27/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 25984.8887 - val_loss: 22761.4297\n",
            "Epoch 28/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 25981.3789 - val_loss: 22758.4727\n",
            "Epoch 29/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 25977.9355 - val_loss: 22755.8672\n",
            "Epoch 30/1000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 25974.5664 - val_loss: 22753.2539\n",
            "Epoch 31/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 25971.2402 - val_loss: 22750.6797\n",
            "Epoch 32/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 25967.8496 - val_loss: 22747.7617\n",
            "Epoch 33/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 25964.3691 - val_loss: 22744.4434\n",
            "Epoch 34/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 25960.9414 - val_loss: 22741.6582\n",
            "Epoch 35/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 25957.4727 - val_loss: 22738.9102\n",
            "Epoch 36/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 25954.1133 - val_loss: 22736.3516\n",
            "Epoch 37/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 25950.6152 - val_loss: 22733.6191\n",
            "Epoch 38/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 25947.1699 - val_loss: 22730.7422\n",
            "Epoch 39/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 25943.8242 - val_loss: 22728.0059\n",
            "Epoch 40/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 25940.4961 - val_loss: 22725.3828\n",
            "Epoch 41/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 25936.9668 - val_loss: 22722.7070\n",
            "Epoch 42/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 25933.5039 - val_loss: 22720.1230\n",
            "Epoch 43/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 25930.0742 - val_loss: 22717.5176\n",
            "Epoch 44/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 25926.7656 - val_loss: 22714.9082\n",
            "Epoch 45/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 25923.3262 - val_loss: 22712.1621\n",
            "Epoch 46/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 25919.8750 - val_loss: 22709.4766\n",
            "Epoch 47/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 25916.5703 - val_loss: 22706.9355\n",
            "Epoch 48/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 25913.2148 - val_loss: 22704.4609\n",
            "Epoch 49/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 25909.9062 - val_loss: 22701.8848\n",
            "Epoch 50/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 25906.5605 - val_loss: 22699.3066\n",
            "Epoch 51/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 25903.2148 - val_loss: 22696.7930\n",
            "Epoch 52/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 25899.8242 - val_loss: 22694.0586\n",
            "Epoch 53/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 25896.3711 - val_loss: 22691.1719\n",
            "Epoch 54/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 25892.9180 - val_loss: 22688.5488\n",
            "Epoch 55/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 25889.2910 - val_loss: 22686.4551\n",
            "Epoch 56/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 25885.5039 - val_loss: 22684.3027\n",
            "Epoch 57/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 25881.7852 - val_loss: 22681.7305\n",
            "Epoch 58/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 25878.0488 - val_loss: 22679.1777\n",
            "Epoch 59/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 25874.2148 - val_loss: 22676.9492\n",
            "Epoch 60/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 25870.5859 - val_loss: 22674.4102\n",
            "Epoch 61/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 25867.1074 - val_loss: 22671.7891\n",
            "Epoch 62/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 25863.7559 - val_loss: 22669.2363\n",
            "Epoch 63/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 25860.4336 - val_loss: 22666.8066\n",
            "Epoch 64/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 25857.2031 - val_loss: 22664.2578\n",
            "Epoch 65/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 25853.9453 - val_loss: 22661.7422\n",
            "Epoch 66/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 25850.5723 - val_loss: 22659.1406\n",
            "Epoch 67/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 25847.1621 - val_loss: 22656.6113\n",
            "Epoch 68/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 25843.7402 - val_loss: 22654.0527\n",
            "Epoch 69/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 25840.3652 - val_loss: 22651.6328\n",
            "Epoch 70/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 25836.7930 - val_loss: 22649.0469\n",
            "Epoch 71/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 25833.1816 - val_loss: 22646.2891\n",
            "Epoch 72/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 25829.7852 - val_loss: 22643.7637\n",
            "Epoch 73/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 25826.4355 - val_loss: 22641.2168\n",
            "Epoch 74/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 25823.0859 - val_loss: 22638.7031\n",
            "Epoch 75/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 25819.6934 - val_loss: 22636.0898\n",
            "Epoch 76/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 25816.2773 - val_loss: 22633.4668\n",
            "Epoch 77/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 25812.7363 - val_loss: 22630.8672\n",
            "Epoch 78/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 25809.2188 - val_loss: 22628.0586\n",
            "Epoch 79/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 25805.7344 - val_loss: 22625.2070\n",
            "Epoch 80/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 25802.2715 - val_loss: 22622.6074\n",
            "Epoch 81/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 25798.7656 - val_loss: 22620.2266\n",
            "Epoch 82/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 25795.1777 - val_loss: 22617.5820\n",
            "Epoch 83/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 25791.5410 - val_loss: 22614.9746\n",
            "Epoch 84/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 25788.1426 - val_loss: 22612.3125\n",
            "Epoch 85/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 25784.6562 - val_loss: 22609.5410\n",
            "Epoch 86/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 25781.2148 - val_loss: 22606.9980\n",
            "Epoch 87/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 25777.8535 - val_loss: 22604.4824\n",
            "Epoch 88/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 25774.4922 - val_loss: 22601.7305\n",
            "Epoch 89/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 25771.1836 - val_loss: 22599.1660\n",
            "Epoch 90/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 25767.8477 - val_loss: 22596.7168\n",
            "Epoch 91/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 25764.3574 - val_loss: 22594.2227\n",
            "Epoch 92/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 25760.8105 - val_loss: 22591.8926\n",
            "Epoch 93/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 25757.2637 - val_loss: 22589.4219\n",
            "Epoch 94/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 25753.7051 - val_loss: 22586.8672\n",
            "Epoch 95/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 25750.2812 - val_loss: 22584.4160\n",
            "Epoch 96/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 25746.9570 - val_loss: 22581.9473\n",
            "Epoch 97/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 25743.6602 - val_loss: 22579.5703\n",
            "Epoch 98/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 25740.3340 - val_loss: 22577.2246\n",
            "Epoch 99/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 25736.7871 - val_loss: 22574.9023\n",
            "Epoch 100/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 25733.2559 - val_loss: 22572.5762\n",
            "Epoch 101/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 25729.8496 - val_loss: 22570.0527\n",
            "Epoch 102/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 25726.5586 - val_loss: 22567.5273\n",
            "Epoch 103/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 25723.1816 - val_loss: 22564.8926\n",
            "Epoch 104/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 25719.6289 - val_loss: 22562.2441\n",
            "Epoch 105/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 25716.1016 - val_loss: 22559.5957\n",
            "Epoch 106/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 25712.7617 - val_loss: 22557.1973\n",
            "Epoch 107/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 25709.4336 - val_loss: 22554.8145\n",
            "Epoch 108/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 25706.1367 - val_loss: 22552.3203\n",
            "Epoch 109/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 25702.6172 - val_loss: 22549.9570\n",
            "Epoch 110/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 25699.0234 - val_loss: 22547.5215\n",
            "Epoch 111/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 25695.6309 - val_loss: 22545.0957\n",
            "Epoch 112/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 25692.0898 - val_loss: 22542.6621\n",
            "Epoch 113/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 25688.5332 - val_loss: 22540.3477\n",
            "Epoch 114/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 25684.8555 - val_loss: 22538.0723\n",
            "Epoch 115/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 25681.3320 - val_loss: 22535.6992\n",
            "Epoch 116/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 25677.9102 - val_loss: 22533.4629\n",
            "Epoch 117/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 25674.4727 - val_loss: 22531.1172\n",
            "Epoch 118/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 25670.9570 - val_loss: 22528.9824\n",
            "Epoch 119/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 25667.2715 - val_loss: 22526.8027\n",
            "Epoch 120/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 25663.5664 - val_loss: 22524.2422\n",
            "Epoch 121/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 25660.0000 - val_loss: 22521.5020\n",
            "Epoch 122/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 25656.2598 - val_loss: 22518.7793\n",
            "Epoch 123/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 25652.4902 - val_loss: 22516.3145\n",
            "Epoch 124/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 25648.8477 - val_loss: 22513.7227\n",
            "Epoch 125/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 25645.3965 - val_loss: 22511.1699\n",
            "Epoch 126/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 25641.8945 - val_loss: 22508.6973\n",
            "Epoch 127/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 25638.5234 - val_loss: 22506.2734\n",
            "Epoch 128/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 25635.1680 - val_loss: 22503.9668\n",
            "Epoch 129/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 25631.7754 - val_loss: 22501.6211\n",
            "Epoch 130/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 25628.2949 - val_loss: 22499.1699\n",
            "Epoch 131/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 25624.8535 - val_loss: 22496.7363\n",
            "Epoch 132/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 25621.3887 - val_loss: 22494.6035\n",
            "Epoch 133/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 25617.9609 - val_loss: 22491.9082\n",
            "Epoch 134/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 25614.4590 - val_loss: 22489.1406\n",
            "Epoch 135/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 25610.9609 - val_loss: 22486.3105\n",
            "Epoch 136/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 25607.5977 - val_loss: 22483.9043\n",
            "Epoch 137/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 25604.1074 - val_loss: 22481.6777\n",
            "Epoch 138/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 25600.7285 - val_loss: 22479.3789\n",
            "Epoch 139/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 25597.3125 - val_loss: 22476.9805\n",
            "Epoch 140/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 25593.7109 - val_loss: 22474.4434\n",
            "Epoch 141/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 25589.9941 - val_loss: 22472.1680\n",
            "Epoch 142/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 25586.4609 - val_loss: 22469.6699\n",
            "Epoch 143/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 25582.9004 - val_loss: 22467.5762\n",
            "Epoch 144/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 25579.4512 - val_loss: 22465.3809\n",
            "Epoch 145/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 25576.0996 - val_loss: 22462.8887\n",
            "Epoch 146/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 25572.6562 - val_loss: 22460.6602\n",
            "Epoch 147/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 25569.1777 - val_loss: 22458.4805\n",
            "Epoch 148/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 25565.6152 - val_loss: 22456.3477\n",
            "Epoch 149/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 25562.2148 - val_loss: 22453.9316\n",
            "Epoch 150/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 25558.8047 - val_loss: 22451.4121\n",
            "Epoch 151/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 25555.3730 - val_loss: 22448.9805\n",
            "Epoch 152/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 25551.8926 - val_loss: 22446.7461\n",
            "Epoch 153/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 25548.4570 - val_loss: 22444.3125\n",
            "Epoch 154/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 25545.0137 - val_loss: 22441.4980\n",
            "Epoch 155/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 25541.4824 - val_loss: 22438.9766\n",
            "Epoch 156/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 25537.9941 - val_loss: 22436.6738\n",
            "Epoch 157/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 25534.6855 - val_loss: 22434.1152\n",
            "Epoch 158/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 25531.3398 - val_loss: 22431.6113\n",
            "Epoch 159/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 25527.9492 - val_loss: 22429.3398\n",
            "Epoch 160/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 25524.6426 - val_loss: 22427.0762\n",
            "Epoch 161/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 25521.3262 - val_loss: 22424.8965\n",
            "Epoch 162/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 25517.9492 - val_loss: 22422.5645\n",
            "Epoch 163/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 25514.5332 - val_loss: 22420.2070\n",
            "Epoch 164/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 25511.2559 - val_loss: 22417.7012\n",
            "Epoch 165/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 25507.9355 - val_loss: 22415.3750\n",
            "Epoch 166/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 25504.6680 - val_loss: 22413.0371\n",
            "Epoch 167/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 25501.3887 - val_loss: 22410.7812\n",
            "Epoch 168/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 25498.0938 - val_loss: 22408.2832\n",
            "Epoch 169/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 25494.6836 - val_loss: 22405.8672\n",
            "Epoch 170/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 25491.3691 - val_loss: 22403.6543\n",
            "Epoch 171/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 25487.8301 - val_loss: 22401.4609\n",
            "Epoch 172/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 25484.3594 - val_loss: 22399.2637\n",
            "Epoch 173/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 25480.8125 - val_loss: 22396.8691\n",
            "Epoch 174/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 25477.2578 - val_loss: 22394.4824\n",
            "Epoch 175/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 25473.6855 - val_loss: 22392.1172\n",
            "Epoch 176/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 25470.0801 - val_loss: 22390.4180\n",
            "Epoch 177/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 25466.5273 - val_loss: 22388.3125\n",
            "Epoch 178/1000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 25463.1250 - val_loss: 22386.1621\n",
            "Epoch 179/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 25459.8184 - val_loss: 22384.0098\n",
            "Epoch 180/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 25456.4844 - val_loss: 22381.8164\n",
            "Epoch 181/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 25453.0684 - val_loss: 22379.4941\n",
            "Epoch 182/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 25449.8105 - val_loss: 22377.3145\n",
            "Epoch 183/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 25446.3516 - val_loss: 22375.1719\n",
            "Epoch 184/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 25443.1074 - val_loss: 22372.7324\n",
            "Epoch 185/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 25439.7559 - val_loss: 22370.2969\n",
            "Epoch 186/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 25436.3691 - val_loss: 22367.7773\n",
            "Epoch 187/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 25432.8730 - val_loss: 22365.8184\n",
            "Epoch 188/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 25429.2969 - val_loss: 22363.9355\n",
            "Epoch 189/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 25425.8418 - val_loss: 22361.9043\n",
            "Epoch 190/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 25422.2520 - val_loss: 22359.6914\n",
            "Epoch 191/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 25418.8242 - val_loss: 22357.4375\n",
            "Epoch 192/1000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 25415.4355 - val_loss: 22354.8594\n",
            "Epoch 193/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 25412.0801 - val_loss: 22352.5840\n",
            "Epoch 194/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 25408.8008 - val_loss: 22350.3379\n",
            "Epoch 195/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 25405.3438 - val_loss: 22347.9434\n",
            "Epoch 196/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 25401.8281 - val_loss: 22345.3340\n",
            "Epoch 197/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 25398.2461 - val_loss: 22343.4277\n",
            "Epoch 198/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 25394.6797 - val_loss: 22341.3379\n",
            "Epoch 199/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 25391.2578 - val_loss: 22339.0625\n",
            "Epoch 200/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 25387.7656 - val_loss: 22336.7930\n",
            "Epoch 201/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 25384.2031 - val_loss: 22334.4023\n",
            "Epoch 202/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 25380.6113 - val_loss: 22332.2754\n",
            "Epoch 203/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 25376.9512 - val_loss: 22330.4551\n",
            "Epoch 204/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 25373.3887 - val_loss: 22328.1543\n",
            "Epoch 205/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 25369.8008 - val_loss: 22325.7676\n",
            "Epoch 206/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 25366.4961 - val_loss: 22323.5566\n",
            "Epoch 207/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 25363.1074 - val_loss: 22321.2754\n",
            "Epoch 208/1000\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 25359.6855 - val_loss: 22318.9824\n",
            "Epoch 209/1000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 25356.3281 - val_loss: 22316.7305\n",
            "Epoch 210/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 25352.9316 - val_loss: 22314.6230\n",
            "Epoch 211/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 25349.5605 - val_loss: 22312.1934\n",
            "Epoch 212/1000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 25346.1445 - val_loss: 22309.9492\n",
            "Epoch 213/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 25342.6602 - val_loss: 22307.6934\n",
            "Epoch 214/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 25339.0801 - val_loss: 22305.4043\n",
            "Epoch 215/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 25335.5918 - val_loss: 22302.9121\n",
            "Epoch 216/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 25332.0820 - val_loss: 22300.7520\n",
            "Epoch 217/1000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 25328.5859 - val_loss: 22298.3027\n",
            "Epoch 218/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 25325.0645 - val_loss: 22296.1875\n",
            "Epoch 219/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 25321.5273 - val_loss: 22294.0254\n",
            "Epoch 220/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 25318.1016 - val_loss: 22291.9727\n",
            "Epoch 221/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 25314.5430 - val_loss: 22289.9336\n",
            "Epoch 222/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 25311.2598 - val_loss: 22287.7539\n",
            "Epoch 223/1000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 25307.9355 - val_loss: 22285.5566\n",
            "Epoch 224/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 25304.4785 - val_loss: 22283.3223\n",
            "Epoch 225/1000\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 25301.0371 - val_loss: 22280.8047\n",
            "Epoch 226/1000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 25297.5859 - val_loss: 22278.5859\n",
            "Epoch 227/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 25294.3789 - val_loss: 22276.4277\n",
            "Epoch 228/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 25291.0371 - val_loss: 22274.2871\n",
            "Epoch 229/1000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 25287.6875 - val_loss: 22272.0703\n",
            "Epoch 230/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 25284.1133 - val_loss: 22270.3828\n",
            "Epoch 231/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 25280.5391 - val_loss: 22268.1230\n",
            "Epoch 232/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 25277.1816 - val_loss: 22265.9922\n",
            "Epoch 233/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 25273.8164 - val_loss: 22263.8848\n",
            "Epoch 234/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 25270.3203 - val_loss: 22261.4297\n",
            "Epoch 235/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 25267.0000 - val_loss: 22259.2871\n",
            "Epoch 236/1000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 25263.6465 - val_loss: 22257.0840\n",
            "Epoch 237/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 25260.2031 - val_loss: 22254.8398\n",
            "Epoch 238/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 25256.7188 - val_loss: 22252.5312\n",
            "Epoch 239/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 25253.2656 - val_loss: 22250.4473\n",
            "Epoch 240/1000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 25249.8242 - val_loss: 22248.4805\n",
            "Epoch 241/1000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 25246.2754 - val_loss: 22246.4629\n",
            "Epoch 242/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 25242.8477 - val_loss: 22244.4688\n",
            "Epoch 243/1000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 25239.4961 - val_loss: 22242.0527\n",
            "Epoch 244/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 25236.0996 - val_loss: 22239.8594\n",
            "Epoch 245/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 25232.6523 - val_loss: 22238.1172\n",
            "Epoch 246/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 25229.1758 - val_loss: 22236.0820\n",
            "Epoch 247/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 25225.7031 - val_loss: 22233.9434\n",
            "Epoch 248/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 25222.1211 - val_loss: 22231.9590\n",
            "Epoch 249/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 25218.6719 - val_loss: 22229.8594\n",
            "Epoch 250/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 25215.3828 - val_loss: 22227.8320\n",
            "Epoch 251/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 25211.8125 - val_loss: 22226.2188\n",
            "Epoch 252/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 25208.1621 - val_loss: 22224.4922\n",
            "Epoch 253/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 25204.5469 - val_loss: 22222.4922\n",
            "Epoch 254/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 25201.0547 - val_loss: 22220.4453\n",
            "Epoch 255/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 25197.5703 - val_loss: 22218.2227\n",
            "Epoch 256/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 25193.9707 - val_loss: 22216.0312\n",
            "Epoch 257/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 25190.3340 - val_loss: 22213.9922\n",
            "Epoch 258/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 25186.9258 - val_loss: 22211.9980\n",
            "Epoch 259/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 25183.4355 - val_loss: 22210.3633\n",
            "Epoch 260/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 25179.8281 - val_loss: 22208.2422\n",
            "Epoch 261/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 25176.5137 - val_loss: 22206.0723\n",
            "Epoch 262/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 25173.2148 - val_loss: 22203.6836\n",
            "Epoch 263/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 25169.8887 - val_loss: 22201.4570\n",
            "Epoch 264/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 25166.5215 - val_loss: 22198.9980\n",
            "Epoch 265/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 25163.1641 - val_loss: 22196.7812\n",
            "Epoch 266/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 25159.8945 - val_loss: 22194.4980\n",
            "Epoch 267/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 25156.6309 - val_loss: 22192.2051\n",
            "Epoch 268/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 25153.1680 - val_loss: 22189.9316\n",
            "Epoch 269/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 25149.5898 - val_loss: 22187.6680\n",
            "Epoch 270/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 25146.0000 - val_loss: 22185.8477\n",
            "Epoch 271/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 25142.6309 - val_loss: 22183.8965\n",
            "Epoch 272/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 25139.0566 - val_loss: 22182.3418\n",
            "Epoch 273/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 25135.4707 - val_loss: 22180.4043\n",
            "Epoch 274/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 25131.8496 - val_loss: 22178.5449\n",
            "Epoch 275/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 25128.2754 - val_loss: 22176.4551\n",
            "Epoch 276/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 25124.8691 - val_loss: 22174.3145\n",
            "Epoch 277/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 25121.5156 - val_loss: 22172.0801\n",
            "Epoch 278/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 25118.1074 - val_loss: 22169.7363\n",
            "Epoch 279/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 25114.7500 - val_loss: 22167.3867\n",
            "Epoch 280/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 25111.4570 - val_loss: 22165.2441\n",
            "Epoch 281/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 25108.1699 - val_loss: 22163.2246\n",
            "Epoch 282/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 25104.7168 - val_loss: 22161.3340\n",
            "Epoch 283/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 25101.2637 - val_loss: 22159.3008\n",
            "Epoch 284/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 25097.9121 - val_loss: 22157.2500\n",
            "Epoch 285/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 25094.5352 - val_loss: 22155.2891\n",
            "Epoch 286/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 25091.0879 - val_loss: 22152.9219\n",
            "Epoch 287/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 25087.5977 - val_loss: 22150.8457\n",
            "Epoch 288/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 25084.1719 - val_loss: 22148.7832\n",
            "Epoch 289/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 25080.8418 - val_loss: 22146.6172\n",
            "Epoch 290/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 25077.5586 - val_loss: 22144.6074\n",
            "Epoch 291/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 25074.2715 - val_loss: 22142.5449\n",
            "Epoch 292/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 25070.7988 - val_loss: 22140.5078\n",
            "Epoch 293/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 25067.3223 - val_loss: 22138.4023\n",
            "Epoch 294/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 25063.9863 - val_loss: 22136.3574\n",
            "Epoch 295/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 25060.7109 - val_loss: 22134.2383\n",
            "Epoch 296/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 25057.2402 - val_loss: 22131.9961\n",
            "Epoch 297/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 25053.7871 - val_loss: 22129.9219\n",
            "Epoch 298/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 25050.3691 - val_loss: 22127.6152\n",
            "Epoch 299/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 25046.9512 - val_loss: 22125.4922\n",
            "Epoch 300/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 25043.5488 - val_loss: 22123.2305\n",
            "Epoch 301/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 25040.3027 - val_loss: 22121.0273\n",
            "Epoch 302/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 25036.9688 - val_loss: 22118.9297\n",
            "Epoch 303/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 25033.5781 - val_loss: 22116.9355\n",
            "Epoch 304/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 25030.1758 - val_loss: 22114.9297\n",
            "Epoch 305/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 25026.8809 - val_loss: 22112.7676\n",
            "Epoch 306/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 25023.6602 - val_loss: 22110.7871\n",
            "Epoch 307/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 25020.5332 - val_loss: 22108.9551\n",
            "Epoch 308/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 25017.1641 - val_loss: 22107.1602\n",
            "Epoch 309/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 25013.8320 - val_loss: 22105.1621\n",
            "Epoch 310/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 25010.4141 - val_loss: 22102.4824\n",
            "Epoch 311/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 25006.9668 - val_loss: 22100.5117\n",
            "Epoch 312/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 25003.5605 - val_loss: 22098.4863\n",
            "Epoch 313/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 25000.1504 - val_loss: 22096.7031\n",
            "Epoch 314/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24996.5410 - val_loss: 22094.9805\n",
            "Epoch 315/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24993.0566 - val_loss: 22092.9121\n",
            "Epoch 316/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 24989.5898 - val_loss: 22090.4707\n",
            "Epoch 317/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 24986.1875 - val_loss: 22088.4121\n",
            "Epoch 318/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24982.7480 - val_loss: 22087.0547\n",
            "Epoch 319/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 24979.2754 - val_loss: 22085.1094\n",
            "Epoch 320/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24975.8359 - val_loss: 22083.0371\n",
            "Epoch 321/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24972.3145 - val_loss: 22080.6387\n",
            "Epoch 322/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 24968.7812 - val_loss: 22078.4727\n",
            "Epoch 323/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 24965.3008 - val_loss: 22076.3691\n",
            "Epoch 324/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 24961.9238 - val_loss: 22074.2285\n",
            "Epoch 325/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 24958.5840 - val_loss: 22072.0840\n",
            "Epoch 326/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24955.4043 - val_loss: 22069.9219\n",
            "Epoch 327/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24952.0762 - val_loss: 22067.5645\n",
            "Epoch 328/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24948.7227 - val_loss: 22065.7441\n",
            "Epoch 329/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 24945.3594 - val_loss: 22063.7031\n",
            "Epoch 330/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 24942.1777 - val_loss: 22061.7773\n",
            "Epoch 331/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 24938.9316 - val_loss: 22059.7031\n",
            "Epoch 332/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 24935.5996 - val_loss: 22057.9941\n",
            "Epoch 333/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 24932.1523 - val_loss: 22056.6602\n",
            "Epoch 334/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 24928.6777 - val_loss: 22054.7266\n",
            "Epoch 335/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24925.2695 - val_loss: 22052.8535\n",
            "Epoch 336/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 24921.7246 - val_loss: 22050.9609\n",
            "Epoch 337/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 24918.3535 - val_loss: 22048.6484\n",
            "Epoch 338/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 24915.0000 - val_loss: 22046.7695\n",
            "Epoch 339/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 24911.6484 - val_loss: 22045.0332\n",
            "Epoch 340/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 24908.3516 - val_loss: 22043.1465\n",
            "Epoch 341/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 24905.0430 - val_loss: 22041.1777\n",
            "Epoch 342/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 24901.6797 - val_loss: 22039.0957\n",
            "Epoch 343/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 24898.3203 - val_loss: 22037.0957\n",
            "Epoch 344/1000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 24895.1055 - val_loss: 22035.1797\n",
            "Epoch 345/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 24891.6934 - val_loss: 22033.2344\n",
            "Epoch 346/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 24888.2441 - val_loss: 22031.5879\n",
            "Epoch 347/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 24884.8164 - val_loss: 22029.5586\n",
            "Epoch 348/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 24881.4277 - val_loss: 22027.0195\n",
            "Epoch 349/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 24878.0508 - val_loss: 22024.8340\n",
            "Epoch 350/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 24874.4980 - val_loss: 22022.7578\n",
            "Epoch 351/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 24870.8887 - val_loss: 22020.9922\n",
            "Epoch 352/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 24867.3770 - val_loss: 22019.1367\n",
            "Epoch 353/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 24864.0449 - val_loss: 22017.2500\n",
            "Epoch 354/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 24860.7109 - val_loss: 22015.3066\n",
            "Epoch 355/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 24857.3340 - val_loss: 22012.9785\n",
            "Epoch 356/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 24854.0957 - val_loss: 22010.9004\n",
            "Epoch 357/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 24850.9355 - val_loss: 22008.8848\n",
            "Epoch 358/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 24847.6523 - val_loss: 22006.9688\n",
            "Epoch 359/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 24844.4219 - val_loss: 22005.1465\n",
            "Epoch 360/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 24841.1895 - val_loss: 22003.2070\n",
            "Epoch 361/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 24837.9238 - val_loss: 22001.1172\n",
            "Epoch 362/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 24834.5957 - val_loss: 21999.0723\n",
            "Epoch 363/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 24831.3164 - val_loss: 21997.1816\n",
            "Epoch 364/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 24827.9453 - val_loss: 21995.4004\n",
            "Epoch 365/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 24824.5078 - val_loss: 21993.6523\n",
            "Epoch 366/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 24821.1816 - val_loss: 21991.5566\n",
            "Epoch 367/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 24817.7715 - val_loss: 21989.6855\n",
            "Epoch 368/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 24814.3008 - val_loss: 21987.8203\n",
            "Epoch 369/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 24811.0254 - val_loss: 21985.9980\n",
            "Epoch 370/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 24807.7559 - val_loss: 21984.4062\n",
            "Epoch 371/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 24804.3223 - val_loss: 21982.6055\n",
            "Epoch 372/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 24800.9414 - val_loss: 21980.6582\n",
            "Epoch 373/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 24797.6562 - val_loss: 21978.4121\n",
            "Epoch 374/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 24794.3945 - val_loss: 21976.5371\n",
            "Epoch 375/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 24791.1523 - val_loss: 21974.5020\n",
            "Epoch 376/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 24787.7852 - val_loss: 21972.3066\n",
            "Epoch 377/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 24784.2910 - val_loss: 21969.9023\n",
            "Epoch 378/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 24780.9453 - val_loss: 21967.4844\n",
            "Epoch 379/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24777.5645 - val_loss: 21965.0664\n",
            "Epoch 380/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24774.1387 - val_loss: 21963.0117\n",
            "Epoch 381/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24770.7754 - val_loss: 21961.0703\n",
            "Epoch 382/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 24767.4258 - val_loss: 21959.2070\n",
            "Epoch 383/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24764.1582 - val_loss: 21957.4316\n",
            "Epoch 384/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 24760.8164 - val_loss: 21955.7324\n",
            "Epoch 385/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24757.3164 - val_loss: 21953.7480\n",
            "Epoch 386/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24753.7969 - val_loss: 21951.9434\n",
            "Epoch 387/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 24750.2461 - val_loss: 21950.0723\n",
            "Epoch 388/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24746.8223 - val_loss: 21948.4297\n",
            "Epoch 389/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 24743.4922 - val_loss: 21946.6387\n",
            "Epoch 390/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24740.2285 - val_loss: 21945.0391\n",
            "Epoch 391/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 24736.9492 - val_loss: 21943.4414\n",
            "Epoch 392/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 24733.5977 - val_loss: 21941.5879\n",
            "Epoch 393/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24730.3652 - val_loss: 21939.9102\n",
            "Epoch 394/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24727.0000 - val_loss: 21938.2930\n",
            "Epoch 395/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 24723.6543 - val_loss: 21936.5273\n",
            "Epoch 396/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24720.2324 - val_loss: 21933.8223\n",
            "Epoch 397/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24716.7969 - val_loss: 21931.6602\n",
            "Epoch 398/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 24713.4355 - val_loss: 21929.9180\n",
            "Epoch 399/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 24710.0020 - val_loss: 21928.2383\n",
            "Epoch 400/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 24706.5215 - val_loss: 21926.3535\n",
            "Epoch 401/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 24703.1152 - val_loss: 21924.7578\n",
            "Epoch 402/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 24699.6660 - val_loss: 21923.1914\n",
            "Epoch 403/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24696.2949 - val_loss: 21921.3027\n",
            "Epoch 404/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24692.9883 - val_loss: 21919.3770\n",
            "Epoch 405/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 24689.5469 - val_loss: 21917.4902\n",
            "Epoch 406/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 24686.2383 - val_loss: 21915.8027\n",
            "Epoch 407/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 24682.9609 - val_loss: 21914.2383\n",
            "Epoch 408/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 24679.4980 - val_loss: 21912.9609\n",
            "Epoch 409/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24675.9941 - val_loss: 21911.5098\n",
            "Epoch 410/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 24672.5840 - val_loss: 21909.9180\n",
            "Epoch 411/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 24669.3008 - val_loss: 21908.2168\n",
            "Epoch 412/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24665.8633 - val_loss: 21906.6973\n",
            "Epoch 413/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 24662.4219 - val_loss: 21904.7578\n",
            "Epoch 414/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 24658.9688 - val_loss: 21902.8418\n",
            "Epoch 415/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24655.6211 - val_loss: 21901.1699\n",
            "Epoch 416/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 24652.3633 - val_loss: 21899.3340\n",
            "Epoch 417/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 24648.9863 - val_loss: 21897.6621\n",
            "Epoch 418/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24645.4844 - val_loss: 21895.8809\n",
            "Epoch 419/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 24641.9551 - val_loss: 21894.2051\n",
            "Epoch 420/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 24638.5176 - val_loss: 21892.1367\n",
            "Epoch 421/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 24635.0371 - val_loss: 21890.2578\n",
            "Epoch 422/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 24631.6680 - val_loss: 21888.4492\n",
            "Epoch 423/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 24628.4453 - val_loss: 21886.7031\n",
            "Epoch 424/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24625.2090 - val_loss: 21884.9316\n",
            "Epoch 425/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 24621.9883 - val_loss: 21883.1406\n",
            "Epoch 426/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24618.5605 - val_loss: 21881.5527\n",
            "Epoch 427/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 24615.0449 - val_loss: 21879.9395\n",
            "Epoch 428/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 24611.7051 - val_loss: 21878.1016\n",
            "Epoch 429/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24608.3945 - val_loss: 21876.3594\n",
            "Epoch 430/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24605.1113 - val_loss: 21874.8027\n",
            "Epoch 431/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 24601.7852 - val_loss: 21873.1738\n",
            "Epoch 432/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 24598.4160 - val_loss: 21871.5820\n",
            "Epoch 433/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 24595.0195 - val_loss: 21869.9551\n",
            "Epoch 434/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 24591.6738 - val_loss: 21868.3027\n",
            "Epoch 435/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 24588.3164 - val_loss: 21866.8906\n",
            "Epoch 436/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24584.8418 - val_loss: 21865.6074\n",
            "Epoch 437/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 24581.3086 - val_loss: 21863.7188\n",
            "Epoch 438/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24577.9609 - val_loss: 21862.0879\n",
            "Epoch 439/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 24574.5352 - val_loss: 21860.5918\n",
            "Epoch 440/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24571.0586 - val_loss: 21858.9414\n",
            "Epoch 441/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 24567.5469 - val_loss: 21857.2520\n",
            "Epoch 442/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 24564.2969 - val_loss: 21855.6777\n",
            "Epoch 443/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 24560.9688 - val_loss: 21854.0957\n",
            "Epoch 444/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 24557.5781 - val_loss: 21852.5918\n",
            "Epoch 445/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24554.2852 - val_loss: 21851.1094\n",
            "Epoch 446/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24550.9316 - val_loss: 21849.0469\n",
            "Epoch 447/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 24547.6836 - val_loss: 21847.1582\n",
            "Epoch 448/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24544.3574 - val_loss: 21845.5879\n",
            "Epoch 449/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 24541.0449 - val_loss: 21844.1270\n",
            "Epoch 450/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 24537.6797 - val_loss: 21842.6133\n",
            "Epoch 451/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 24534.1816 - val_loss: 21841.0684\n",
            "Epoch 452/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 24530.7754 - val_loss: 21839.6270\n",
            "Epoch 453/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 24527.5176 - val_loss: 21838.0273\n",
            "Epoch 454/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 24524.3398 - val_loss: 21836.3574\n",
            "Epoch 455/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 24520.9512 - val_loss: 21835.3203\n",
            "Epoch 456/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24517.3262 - val_loss: 21834.0059\n",
            "Epoch 457/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 24513.9746 - val_loss: 21832.5430\n",
            "Epoch 458/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 24510.4727 - val_loss: 21831.0156\n",
            "Epoch 459/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24507.1465 - val_loss: 21829.3379\n",
            "Epoch 460/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 24503.9238 - val_loss: 21827.1133\n",
            "Epoch 461/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 24500.5469 - val_loss: 21825.0371\n",
            "Epoch 462/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24497.2129 - val_loss: 21823.4434\n",
            "Epoch 463/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 24493.9004 - val_loss: 21821.8574\n",
            "Epoch 464/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 24490.5664 - val_loss: 21820.5254\n",
            "Epoch 465/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 24487.1523 - val_loss: 21819.0684\n",
            "Epoch 466/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 24483.6406 - val_loss: 21817.6953\n",
            "Epoch 467/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24480.2402 - val_loss: 21816.1621\n",
            "Epoch 468/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24476.7676 - val_loss: 21815.1875\n",
            "Epoch 469/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 24473.3086 - val_loss: 21813.8008\n",
            "Epoch 470/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 24469.8691 - val_loss: 21812.4551\n",
            "Epoch 471/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 24466.4395 - val_loss: 21810.7930\n",
            "Epoch 472/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 24463.2246 - val_loss: 21809.3320\n",
            "Epoch 473/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 24459.9824 - val_loss: 21807.7773\n",
            "Epoch 474/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 24456.7656 - val_loss: 21806.3262\n",
            "Epoch 475/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24453.3691 - val_loss: 21804.3418\n",
            "Epoch 476/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24450.0391 - val_loss: 21802.5977\n",
            "Epoch 477/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 24446.6602 - val_loss: 21801.2324\n",
            "Epoch 478/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24443.2148 - val_loss: 21799.8652\n",
            "Epoch 479/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24439.7363 - val_loss: 21798.1621\n",
            "Epoch 480/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 24436.3145 - val_loss: 21796.6211\n",
            "Epoch 481/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 24433.0059 - val_loss: 21794.8984\n",
            "Epoch 482/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 24429.7754 - val_loss: 21793.1211\n",
            "Epoch 483/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 24426.5137 - val_loss: 21791.4727\n",
            "Epoch 484/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24423.2578 - val_loss: 21789.8887\n",
            "Epoch 485/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24419.9609 - val_loss: 21788.3223\n",
            "Epoch 486/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 24416.6777 - val_loss: 21787.0000\n",
            "Epoch 487/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24413.3691 - val_loss: 21785.2715\n",
            "Epoch 488/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 24410.1816 - val_loss: 21783.8691\n",
            "Epoch 489/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 24406.8418 - val_loss: 21782.7695\n",
            "Epoch 490/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 24403.4043 - val_loss: 21781.4414\n",
            "Epoch 491/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24399.9707 - val_loss: 21780.0977\n",
            "Epoch 492/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 24396.6680 - val_loss: 21778.5195\n",
            "Epoch 493/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24393.4082 - val_loss: 21776.9668\n",
            "Epoch 494/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 24390.2207 - val_loss: 21775.0195\n",
            "Epoch 495/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 24387.0234 - val_loss: 21773.4297\n",
            "Epoch 496/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24383.7812 - val_loss: 21771.5977\n",
            "Epoch 497/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24380.5840 - val_loss: 21769.7383\n",
            "Epoch 498/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 24377.3652 - val_loss: 21768.0391\n",
            "Epoch 499/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 24374.1250 - val_loss: 21766.4648\n",
            "Epoch 500/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24370.8613 - val_loss: 21765.0977\n",
            "Epoch 501/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 24367.4355 - val_loss: 21763.5195\n",
            "Epoch 502/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 24364.1699 - val_loss: 21762.1230\n",
            "Epoch 503/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24360.8555 - val_loss: 21760.4473\n",
            "Epoch 504/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24357.5293 - val_loss: 21758.8145\n",
            "Epoch 505/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 24354.0879 - val_loss: 21757.6035\n",
            "Epoch 506/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 24350.6367 - val_loss: 21756.1875\n",
            "Epoch 507/1000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 24347.4004 - val_loss: 21754.3262\n",
            "Epoch 508/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 24343.9238 - val_loss: 21751.6699\n",
            "Epoch 509/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 24340.5918 - val_loss: 21749.4668\n",
            "Epoch 510/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 24337.1934 - val_loss: 21747.8340\n",
            "Epoch 511/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 24333.7402 - val_loss: 21746.5312\n",
            "Epoch 512/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 24330.3477 - val_loss: 21744.9023\n",
            "Epoch 513/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 24327.0996 - val_loss: 21743.6758\n",
            "Epoch 514/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 24323.5469 - val_loss: 21742.3262\n",
            "Epoch 515/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 24320.0645 - val_loss: 21740.9551\n",
            "Epoch 516/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 24316.7402 - val_loss: 21739.4824\n",
            "Epoch 517/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 24313.4961 - val_loss: 21738.0332\n",
            "Epoch 518/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 24310.1875 - val_loss: 21736.5820\n",
            "Epoch 519/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 24306.9629 - val_loss: 21734.9980\n",
            "Epoch 520/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 24303.7363 - val_loss: 21733.6289\n",
            "Epoch 521/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24300.4258 - val_loss: 21732.0332\n",
            "Epoch 522/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24297.0508 - val_loss: 21730.7266\n",
            "Epoch 523/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 24293.7305 - val_loss: 21729.0918\n",
            "Epoch 524/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 24290.4961 - val_loss: 21727.6289\n",
            "Epoch 525/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 24287.2754 - val_loss: 21726.1152\n",
            "Epoch 526/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 24284.0547 - val_loss: 21724.6582\n",
            "Epoch 527/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 24280.8418 - val_loss: 21723.3887\n",
            "Epoch 528/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 24277.5957 - val_loss: 21721.8418\n",
            "Epoch 529/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 24274.2637 - val_loss: 21720.3594\n",
            "Epoch 530/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 24270.9062 - val_loss: 21718.9688\n",
            "Epoch 531/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 24267.6992 - val_loss: 21717.6719\n",
            "Epoch 532/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 24264.3594 - val_loss: 21716.1719\n",
            "Epoch 533/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 24261.0566 - val_loss: 21714.6777\n",
            "Epoch 534/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 24257.6211 - val_loss: 21713.1738\n",
            "Epoch 535/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 24254.0820 - val_loss: 21711.6582\n",
            "Epoch 536/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 24250.6992 - val_loss: 21710.1211\n",
            "Epoch 537/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 24247.4023 - val_loss: 21708.6875\n",
            "Epoch 538/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 24244.1992 - val_loss: 21707.3672\n",
            "Epoch 539/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 24241.0000 - val_loss: 21705.9570\n",
            "Epoch 540/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 24237.5527 - val_loss: 21704.6738\n",
            "Epoch 541/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 24234.2500 - val_loss: 21703.2617\n",
            "Epoch 542/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 24230.9766 - val_loss: 21701.9551\n",
            "Epoch 543/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 24227.6152 - val_loss: 21700.8770\n",
            "Epoch 544/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 24224.2148 - val_loss: 21699.7832\n",
            "Epoch 545/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 24220.8223 - val_loss: 21698.0059\n",
            "Epoch 546/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 24217.5039 - val_loss: 21696.0000\n",
            "Epoch 547/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 24214.1191 - val_loss: 21694.3535\n",
            "Epoch 548/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24210.8438 - val_loss: 21692.4727\n",
            "Epoch 549/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 24207.4355 - val_loss: 21690.7188\n",
            "Epoch 550/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 24203.9766 - val_loss: 21689.7109\n",
            "Epoch 551/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24200.6465 - val_loss: 21688.5000\n",
            "Epoch 552/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 24197.1992 - val_loss: 21687.6973\n",
            "Epoch 553/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24193.7500 - val_loss: 21686.4629\n",
            "Epoch 554/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24190.4336 - val_loss: 21685.0781\n",
            "Epoch 555/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 24187.2012 - val_loss: 21683.6035\n",
            "Epoch 556/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24183.8008 - val_loss: 21682.7324\n",
            "Epoch 557/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24180.4004 - val_loss: 21681.6367\n",
            "Epoch 558/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 24177.0176 - val_loss: 21680.3281\n",
            "Epoch 559/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 24173.6367 - val_loss: 21679.2715\n",
            "Epoch 560/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24170.1934 - val_loss: 21677.5117\n",
            "Epoch 561/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24166.8438 - val_loss: 21675.9219\n",
            "Epoch 562/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24163.4766 - val_loss: 21674.4883\n",
            "Epoch 563/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 24159.9570 - val_loss: 21673.4023\n",
            "Epoch 564/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 24156.5098 - val_loss: 21672.0273\n",
            "Epoch 565/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24153.2559 - val_loss: 21670.8711\n",
            "Epoch 566/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 24149.9766 - val_loss: 21669.4727\n",
            "Epoch 567/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 24146.7676 - val_loss: 21668.1680\n",
            "Epoch 568/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 24143.3145 - val_loss: 21667.3145\n",
            "Epoch 569/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 24140.0000 - val_loss: 21666.0078\n",
            "Epoch 570/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 24136.7148 - val_loss: 21664.4766\n",
            "Epoch 571/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 24133.3965 - val_loss: 21663.4082\n",
            "Epoch 572/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 24129.8535 - val_loss: 21662.5625\n",
            "Epoch 573/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24126.4961 - val_loss: 21661.2773\n",
            "Epoch 574/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 24123.2695 - val_loss: 21659.8906\n",
            "Epoch 575/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 24120.0508 - val_loss: 21658.3730\n",
            "Epoch 576/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 24116.9121 - val_loss: 21657.0449\n",
            "Epoch 577/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 24113.7051 - val_loss: 21655.7559\n",
            "Epoch 578/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 24110.2891 - val_loss: 21655.0625\n",
            "Epoch 579/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24106.9102 - val_loss: 21653.6172\n",
            "Epoch 580/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24103.6992 - val_loss: 21652.2324\n",
            "Epoch 581/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 24100.4824 - val_loss: 21650.8594\n",
            "Epoch 582/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 24097.1816 - val_loss: 21649.3340\n",
            "Epoch 583/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 24093.8555 - val_loss: 21647.6992\n",
            "Epoch 584/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 24090.5703 - val_loss: 21645.8965\n",
            "Epoch 585/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24087.0898 - val_loss: 21644.7559\n",
            "Epoch 586/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 24083.5742 - val_loss: 21643.6074\n",
            "Epoch 587/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24080.1777 - val_loss: 21642.2227\n",
            "Epoch 588/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24076.8535 - val_loss: 21640.8320\n",
            "Epoch 589/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24073.4727 - val_loss: 21639.5762\n",
            "Epoch 590/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 24070.0645 - val_loss: 21638.1582\n",
            "Epoch 591/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 24066.7617 - val_loss: 21636.8672\n",
            "Epoch 592/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 24063.4141 - val_loss: 21635.3105\n",
            "Epoch 593/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 24060.1387 - val_loss: 21633.6953\n",
            "Epoch 594/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 24056.7793 - val_loss: 21632.2539\n",
            "Epoch 595/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 24053.5410 - val_loss: 21630.9531\n",
            "Epoch 596/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24050.2500 - val_loss: 21629.7324\n",
            "Epoch 597/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 24046.9434 - val_loss: 21628.2070\n",
            "Epoch 598/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24043.6992 - val_loss: 21626.7500\n",
            "Epoch 599/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24040.4531 - val_loss: 21625.3730\n",
            "Epoch 600/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24037.1816 - val_loss: 21624.0332\n",
            "Epoch 601/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24033.9316 - val_loss: 21622.7754\n",
            "Epoch 602/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24030.5430 - val_loss: 21621.2734\n",
            "Epoch 603/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24027.1074 - val_loss: 21619.4883\n",
            "Epoch 604/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 24023.8477 - val_loss: 21618.0410\n",
            "Epoch 605/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24020.4902 - val_loss: 21617.5781\n",
            "Epoch 606/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 24017.1191 - val_loss: 21616.3887\n",
            "Epoch 607/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 24013.9199 - val_loss: 21615.2051\n",
            "Epoch 608/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 24010.7305 - val_loss: 21614.0000\n",
            "Epoch 609/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24007.4961 - val_loss: 21612.7734\n",
            "Epoch 610/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24004.1953 - val_loss: 21611.4473\n",
            "Epoch 611/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 24000.9492 - val_loss: 21610.1426\n",
            "Epoch 612/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 23997.7285 - val_loss: 21608.7871\n",
            "Epoch 613/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23994.3887 - val_loss: 21607.8574\n",
            "Epoch 614/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 23990.8574 - val_loss: 21605.9766\n",
            "Epoch 615/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 23987.4590 - val_loss: 21604.0000\n",
            "Epoch 616/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 23983.9824 - val_loss: 21602.8789\n",
            "Epoch 617/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23980.5996 - val_loss: 21601.1855\n",
            "Epoch 618/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23977.2969 - val_loss: 21599.2480\n",
            "Epoch 619/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 23974.1445 - val_loss: 21597.8340\n",
            "Epoch 620/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23970.9297 - val_loss: 21596.4375\n",
            "Epoch 621/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 23967.6289 - val_loss: 21595.3633\n",
            "Epoch 622/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23964.3223 - val_loss: 21594.5957\n",
            "Epoch 623/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23960.8555 - val_loss: 21593.6465\n",
            "Epoch 624/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 23957.3281 - val_loss: 21592.7422\n",
            "Epoch 625/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 23953.8848 - val_loss: 21591.4082\n",
            "Epoch 626/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23950.6562 - val_loss: 21590.3672\n",
            "Epoch 627/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23947.3594 - val_loss: 21588.8125\n",
            "Epoch 628/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 23944.1621 - val_loss: 21587.4277\n",
            "Epoch 629/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23940.9043 - val_loss: 21586.0977\n",
            "Epoch 630/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 23937.6289 - val_loss: 21585.0371\n",
            "Epoch 631/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23934.0371 - val_loss: 21584.8125\n",
            "Epoch 632/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 23930.5391 - val_loss: 21584.0703\n",
            "Epoch 633/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23927.0293 - val_loss: 21583.2988\n",
            "Epoch 634/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 23923.6836 - val_loss: 21582.1680\n",
            "Epoch 635/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 23920.4023 - val_loss: 21580.9180\n",
            "Epoch 636/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 23916.9922 - val_loss: 21579.5293\n",
            "Epoch 637/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 23913.6875 - val_loss: 21578.0879\n",
            "Epoch 638/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 23910.3848 - val_loss: 21576.6230\n",
            "Epoch 639/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 23907.1562 - val_loss: 21574.9570\n",
            "Epoch 640/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 23903.7969 - val_loss: 21573.6348\n",
            "Epoch 641/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 23900.5352 - val_loss: 21572.5449\n",
            "Epoch 642/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23897.1113 - val_loss: 21571.7363\n",
            "Epoch 643/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 23893.7168 - val_loss: 21570.1211\n",
            "Epoch 644/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 23890.2246 - val_loss: 21568.9277\n",
            "Epoch 645/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 23886.7051 - val_loss: 21567.6621\n",
            "Epoch 646/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 23883.1055 - val_loss: 21566.4023\n",
            "Epoch 647/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 23879.6934 - val_loss: 21564.9180\n",
            "Epoch 648/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23876.4902 - val_loss: 21563.2559\n",
            "Epoch 649/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 23873.1875 - val_loss: 21562.2812\n",
            "Epoch 650/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 23870.0078 - val_loss: 21561.1230\n",
            "Epoch 651/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 23866.6426 - val_loss: 21559.9766\n",
            "Epoch 652/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 23863.1680 - val_loss: 21558.7754\n",
            "Epoch 653/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 23859.8418 - val_loss: 21557.5469\n",
            "Epoch 654/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 23856.4609 - val_loss: 21555.9102\n",
            "Epoch 655/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23853.0801 - val_loss: 21554.7109\n",
            "Epoch 656/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 23849.8008 - val_loss: 21553.4492\n",
            "Epoch 657/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 23846.5293 - val_loss: 21552.0586\n",
            "Epoch 658/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 23843.2285 - val_loss: 21550.4824\n",
            "Epoch 659/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 23839.9824 - val_loss: 21549.0469\n",
            "Epoch 660/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 23836.8008 - val_loss: 21548.0176\n",
            "Epoch 661/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 23833.5410 - val_loss: 21547.1172\n",
            "Epoch 662/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23830.1191 - val_loss: 21546.3906\n",
            "Epoch 663/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23826.7051 - val_loss: 21545.2734\n",
            "Epoch 664/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23823.5410 - val_loss: 21544.0000\n",
            "Epoch 665/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 23820.2344 - val_loss: 21542.8203\n",
            "Epoch 666/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 23817.0137 - val_loss: 21541.3828\n",
            "Epoch 667/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 23813.6777 - val_loss: 21540.2168\n",
            "Epoch 668/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 23810.2832 - val_loss: 21539.2617\n",
            "Epoch 669/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 23806.9980 - val_loss: 21538.0332\n",
            "Epoch 670/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 23803.7676 - val_loss: 21536.6016\n",
            "Epoch 671/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 23800.4082 - val_loss: 21535.3223\n",
            "Epoch 672/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23796.9414 - val_loss: 21534.0996\n",
            "Epoch 673/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 23793.3379 - val_loss: 21533.2988\n",
            "Epoch 674/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23789.9316 - val_loss: 21531.8926\n",
            "Epoch 675/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 23786.6152 - val_loss: 21530.6230\n",
            "Epoch 676/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 23783.2383 - val_loss: 21529.9414\n",
            "Epoch 677/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 23779.8613 - val_loss: 21528.8379\n",
            "Epoch 678/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 23776.5957 - val_loss: 21527.6230\n",
            "Epoch 679/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 23773.3633 - val_loss: 21526.2734\n",
            "Epoch 680/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 23770.2207 - val_loss: 21525.2402\n",
            "Epoch 681/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 23766.9512 - val_loss: 21523.9414\n",
            "Epoch 682/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23763.6543 - val_loss: 21523.0020\n",
            "Epoch 683/1000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 23760.3965 - val_loss: 21521.9297\n",
            "Epoch 684/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 23757.1660 - val_loss: 21520.7578\n",
            "Epoch 685/1000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 23753.9297 - val_loss: 21519.5684\n",
            "Epoch 686/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 23750.8691 - val_loss: 21518.4570\n",
            "Epoch 687/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23747.5898 - val_loss: 21517.0312\n",
            "Epoch 688/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 23744.1816 - val_loss: 21515.9316\n",
            "Epoch 689/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 23740.8477 - val_loss: 21514.4629\n",
            "Epoch 690/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 23737.6016 - val_loss: 21513.1660\n",
            "Epoch 691/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 23734.2598 - val_loss: 21512.4297\n",
            "Epoch 692/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 23730.9297 - val_loss: 21511.4590\n",
            "Epoch 693/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 23727.7344 - val_loss: 21510.1230\n",
            "Epoch 694/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 23724.4355 - val_loss: 21509.1797\n",
            "Epoch 695/1000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 23720.9961 - val_loss: 21507.6172\n",
            "Epoch 696/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 23717.6973 - val_loss: 21506.0254\n",
            "Epoch 697/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 23714.4316 - val_loss: 21505.1797\n",
            "Epoch 698/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 23711.1680 - val_loss: 21503.8965\n",
            "Epoch 699/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 23707.9512 - val_loss: 21502.0723\n",
            "Epoch 700/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 23704.7344 - val_loss: 21500.6758\n",
            "Epoch 701/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 23701.5898 - val_loss: 21499.2129\n",
            "Epoch 702/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 23698.3887 - val_loss: 21497.3027\n",
            "Epoch 703/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 23695.1621 - val_loss: 21495.6973\n",
            "Epoch 704/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 23691.9570 - val_loss: 21493.8125\n",
            "Epoch 705/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 23688.7031 - val_loss: 21492.5547\n",
            "Epoch 706/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23685.5488 - val_loss: 21491.6113\n",
            "Epoch 707/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 23682.3418 - val_loss: 21489.7930\n",
            "Epoch 708/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 23679.1484 - val_loss: 21488.6660\n",
            "Epoch 709/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23675.9141 - val_loss: 21487.8926\n",
            "Epoch 710/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23672.6621 - val_loss: 21487.0879\n",
            "Epoch 711/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 23669.2656 - val_loss: 21486.0996\n",
            "Epoch 712/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23665.8965 - val_loss: 21485.2051\n",
            "Epoch 713/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23662.5664 - val_loss: 21483.5117\n",
            "Epoch 714/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 23659.2090 - val_loss: 21482.6328\n",
            "Epoch 715/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 23655.9004 - val_loss: 21481.4688\n",
            "Epoch 716/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 23652.6816 - val_loss: 21479.8770\n",
            "Epoch 717/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 23649.4844 - val_loss: 21478.8223\n",
            "Epoch 718/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23646.2441 - val_loss: 21477.8379\n",
            "Epoch 719/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 23643.0176 - val_loss: 21476.7578\n",
            "Epoch 720/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 23639.7930 - val_loss: 21476.0605\n",
            "Epoch 721/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23636.4883 - val_loss: 21475.1484\n",
            "Epoch 722/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 23633.1973 - val_loss: 21474.4961\n",
            "Epoch 723/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 23629.9160 - val_loss: 21473.9727\n",
            "Epoch 724/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 23626.6992 - val_loss: 21473.0234\n",
            "Epoch 725/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23623.4258 - val_loss: 21472.2168\n",
            "Epoch 726/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 23620.2012 - val_loss: 21471.2285\n",
            "Epoch 727/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23616.9219 - val_loss: 21469.4473\n",
            "Epoch 728/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23613.5078 - val_loss: 21467.2773\n",
            "Epoch 729/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23609.9258 - val_loss: 21466.4629\n",
            "Epoch 730/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 23606.4707 - val_loss: 21465.2695\n",
            "Epoch 731/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 23602.9160 - val_loss: 21464.8242\n",
            "Epoch 732/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23599.4570 - val_loss: 21464.7793\n",
            "Epoch 733/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23596.0332 - val_loss: 21463.9609\n",
            "Epoch 734/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 23592.6289 - val_loss: 21462.9082\n",
            "Epoch 735/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 23589.1914 - val_loss: 21461.9805\n",
            "Epoch 736/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23585.9375 - val_loss: 21461.0000\n",
            "Epoch 737/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23582.7500 - val_loss: 21459.5703\n",
            "Epoch 738/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 23579.4023 - val_loss: 21458.5332\n",
            "Epoch 739/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 23576.1113 - val_loss: 21457.4375\n",
            "Epoch 740/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23572.8926 - val_loss: 21456.5977\n",
            "Epoch 741/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 23569.5996 - val_loss: 21455.6309\n",
            "Epoch 742/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23566.2207 - val_loss: 21454.9863\n",
            "Epoch 743/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23562.9043 - val_loss: 21454.0918\n",
            "Epoch 744/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23559.7402 - val_loss: 21453.0664\n",
            "Epoch 745/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 23556.6094 - val_loss: 21452.1074\n",
            "Epoch 746/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 23553.4805 - val_loss: 21451.2168\n",
            "Epoch 747/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23550.3301 - val_loss: 21450.5527\n",
            "Epoch 748/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 23547.2031 - val_loss: 21449.9609\n",
            "Epoch 749/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23543.7949 - val_loss: 21450.0508\n",
            "Epoch 750/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 23540.4043 - val_loss: 21449.3828\n",
            "Epoch 751/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 23537.1426 - val_loss: 21448.5645\n",
            "Epoch 752/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23533.9199 - val_loss: 21447.8320\n",
            "Epoch 753/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23530.7344 - val_loss: 21446.8672\n",
            "Epoch 754/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 23527.4121 - val_loss: 21446.1602\n",
            "Epoch 755/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 23524.0000 - val_loss: 21445.4785\n",
            "Epoch 756/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23520.6465 - val_loss: 21444.5938\n",
            "Epoch 757/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23517.4199 - val_loss: 21443.8633\n",
            "Epoch 758/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 23514.1055 - val_loss: 21442.8320\n",
            "Epoch 759/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 23510.9766 - val_loss: 21442.1992\n",
            "Epoch 760/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 23507.6621 - val_loss: 21441.9473\n",
            "Epoch 761/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23504.3848 - val_loss: 21441.0684\n",
            "Epoch 762/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 23501.1758 - val_loss: 21440.0117\n",
            "Epoch 763/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 23498.0195 - val_loss: 21439.2969\n",
            "Epoch 764/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23494.7363 - val_loss: 21438.8535\n",
            "Epoch 765/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 23491.4180 - val_loss: 21438.2637\n",
            "Epoch 766/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 23487.9707 - val_loss: 21436.4492\n",
            "Epoch 767/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23484.5098 - val_loss: 21435.5625\n",
            "Epoch 768/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 23481.2051 - val_loss: 21434.6621\n",
            "Epoch 769/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 23478.0137 - val_loss: 21433.7617\n",
            "Epoch 770/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23474.6875 - val_loss: 21433.9219\n",
            "Epoch 771/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 23471.2793 - val_loss: 21433.3125\n",
            "Epoch 772/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23468.0449 - val_loss: 21432.2500\n",
            "Epoch 773/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23464.9238 - val_loss: 21431.0430\n",
            "Epoch 774/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 23461.6934 - val_loss: 21430.3477\n",
            "Epoch 775/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 23458.4004 - val_loss: 21429.6543\n",
            "Epoch 776/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 23455.1152 - val_loss: 21428.7227\n",
            "Epoch 777/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23452.0391 - val_loss: 21427.7227\n",
            "Epoch 778/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23448.7109 - val_loss: 21427.4414\n",
            "Epoch 779/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 23445.3320 - val_loss: 21426.4316\n",
            "Epoch 780/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 23442.0527 - val_loss: 21425.5977\n",
            "Epoch 781/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23438.7949 - val_loss: 21425.0273\n",
            "Epoch 782/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 23435.5781 - val_loss: 21424.1816\n",
            "Epoch 783/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23432.2715 - val_loss: 21423.2500\n",
            "Epoch 784/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23429.0605 - val_loss: 21422.3535\n",
            "Epoch 785/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 23425.8281 - val_loss: 21421.2285\n",
            "Epoch 786/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 23422.5391 - val_loss: 21420.4277\n",
            "Epoch 787/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 23419.1152 - val_loss: 21419.5430\n",
            "Epoch 788/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23415.7305 - val_loss: 21418.7871\n",
            "Epoch 789/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 23412.4668 - val_loss: 21418.4473\n",
            "Epoch 790/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 23409.1973 - val_loss: 21417.9297\n",
            "Epoch 791/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23405.9297 - val_loss: 21417.4512\n",
            "Epoch 792/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 23402.6914 - val_loss: 21416.6738\n",
            "Epoch 793/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 23399.4941 - val_loss: 21415.3828\n",
            "Epoch 794/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 23396.3633 - val_loss: 21413.8418\n",
            "Epoch 795/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 23393.0879 - val_loss: 21412.6465\n",
            "Epoch 796/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 23389.8125 - val_loss: 21411.6875\n",
            "Epoch 797/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 23386.5059 - val_loss: 21411.1094\n",
            "Epoch 798/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 23383.2266 - val_loss: 21410.0430\n",
            "Epoch 799/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23379.7969 - val_loss: 21409.0645\n",
            "Epoch 800/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 23376.4824 - val_loss: 21408.6855\n",
            "Epoch 801/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 23373.2051 - val_loss: 21408.2324\n",
            "Epoch 802/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23369.9355 - val_loss: 21407.0918\n",
            "Epoch 803/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 23366.6465 - val_loss: 21406.3672\n",
            "Epoch 804/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 23363.3379 - val_loss: 21405.5137\n",
            "Epoch 805/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23360.1699 - val_loss: 21404.9746\n",
            "Epoch 806/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 23356.8477 - val_loss: 21405.2422\n",
            "Epoch 807/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 23353.2676 - val_loss: 21405.2969\n",
            "Epoch 808/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23349.8203 - val_loss: 21404.7070\n",
            "Epoch 809/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23346.5820 - val_loss: 21403.8086\n",
            "Epoch 810/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 23343.1523 - val_loss: 21403.8867\n",
            "Epoch 811/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23339.8203 - val_loss: 21403.0508\n",
            "Epoch 812/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 23336.6777 - val_loss: 21402.2676\n",
            "Epoch 813/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23333.5547 - val_loss: 21401.6543\n",
            "Epoch 814/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23330.3066 - val_loss: 21401.2871\n",
            "Epoch 815/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 23326.9648 - val_loss: 21401.5000\n",
            "Epoch 816/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 23323.4961 - val_loss: 21400.3848\n",
            "Epoch 817/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 23320.0020 - val_loss: 21400.6133\n",
            "Epoch 818/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 23316.6289 - val_loss: 21399.9102\n",
            "Epoch 819/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 23313.3828 - val_loss: 21398.9805\n",
            "Epoch 820/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23310.2812 - val_loss: 21397.7168\n",
            "Epoch 821/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 23307.0488 - val_loss: 21396.1035\n",
            "Epoch 822/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 23303.9355 - val_loss: 21394.6621\n",
            "Epoch 823/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23300.6680 - val_loss: 21393.6094\n",
            "Epoch 824/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 23297.3359 - val_loss: 21393.3281\n",
            "Epoch 825/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 23293.9844 - val_loss: 21392.6973\n",
            "Epoch 826/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 23290.7324 - val_loss: 21391.8691\n",
            "Epoch 827/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 23287.4238 - val_loss: 21390.7305\n",
            "Epoch 828/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 23284.1152 - val_loss: 21390.6504\n",
            "Epoch 829/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 23280.7930 - val_loss: 21390.1094\n",
            "Epoch 830/1000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 23277.5996 - val_loss: 21388.7266\n",
            "Epoch 831/1000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 23274.2285 - val_loss: 21387.7832\n",
            "Epoch 832/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 23270.8867 - val_loss: 21386.9629\n",
            "Epoch 833/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 23267.7148 - val_loss: 21386.0645\n",
            "Epoch 834/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 23264.6191 - val_loss: 21385.2207\n",
            "Epoch 835/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 23261.3105 - val_loss: 21384.7324\n",
            "Epoch 836/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 23257.9980 - val_loss: 21383.9023\n",
            "Epoch 837/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 23254.6934 - val_loss: 21383.0137\n",
            "Epoch 838/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 23251.3633 - val_loss: 21381.6523\n",
            "Epoch 839/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 23248.0117 - val_loss: 21380.7305\n",
            "Epoch 840/1000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 23244.8105 - val_loss: 21379.9492\n",
            "Epoch 841/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 23241.6465 - val_loss: 21378.9492\n",
            "Epoch 842/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 23238.4102 - val_loss: 21378.3105\n",
            "Epoch 843/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 23235.1367 - val_loss: 21377.6914\n",
            "Epoch 844/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 23231.9668 - val_loss: 21376.3867\n",
            "Epoch 845/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 23228.6387 - val_loss: 21375.9277\n",
            "Epoch 846/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 23225.3516 - val_loss: 21375.2734\n",
            "Epoch 847/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 23222.1230 - val_loss: 21374.7402\n",
            "Epoch 848/1000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 23218.9023 - val_loss: 21374.1387\n",
            "Epoch 849/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 23215.7949 - val_loss: 21373.3574\n",
            "Epoch 850/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 23212.4688 - val_loss: 21373.1094\n",
            "Epoch 851/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 23209.2129 - val_loss: 21372.1543\n",
            "Epoch 852/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 23205.8887 - val_loss: 21371.3477\n",
            "Epoch 853/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 23202.6406 - val_loss: 21370.6602\n",
            "Epoch 854/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 23199.2109 - val_loss: 21370.8223\n",
            "Epoch 855/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 23195.9219 - val_loss: 21370.1465\n",
            "Epoch 856/1000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 23192.7812 - val_loss: 21369.3008\n",
            "Epoch 857/1000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 23189.6562 - val_loss: 21368.6035\n",
            "Epoch 858/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 23186.3945 - val_loss: 21368.9160\n",
            "Epoch 859/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23182.9590 - val_loss: 21368.4395\n",
            "Epoch 860/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23179.4512 - val_loss: 21368.3594\n",
            "Epoch 861/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 23176.1016 - val_loss: 21367.6367\n",
            "Epoch 862/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 23172.9746 - val_loss: 21366.8633\n",
            "Epoch 863/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 23169.8789 - val_loss: 21365.8184\n",
            "Epoch 864/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 23166.8398 - val_loss: 21365.1016\n",
            "Epoch 865/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 23163.4902 - val_loss: 21365.1270\n",
            "Epoch 866/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23160.1348 - val_loss: 21364.7168\n",
            "Epoch 867/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 23156.9355 - val_loss: 21363.9004\n",
            "Epoch 868/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 23153.9043 - val_loss: 21363.2871\n",
            "Epoch 869/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23150.6523 - val_loss: 21363.1914\n",
            "Epoch 870/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 23147.3887 - val_loss: 21362.6406\n",
            "Epoch 871/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 23144.1016 - val_loss: 21362.1855\n",
            "Epoch 872/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 23140.8750 - val_loss: 21361.3848\n",
            "Epoch 873/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23137.5801 - val_loss: 21361.0078\n",
            "Epoch 874/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 23134.3906 - val_loss: 21360.4434\n",
            "Epoch 875/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 23131.2500 - val_loss: 21359.5273\n",
            "Epoch 876/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 23128.2188 - val_loss: 21358.7695\n",
            "Epoch 877/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 23125.1230 - val_loss: 21357.7617\n",
            "Epoch 878/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23122.0430 - val_loss: 21356.7031\n",
            "Epoch 879/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23118.9219 - val_loss: 21355.9453\n",
            "Epoch 880/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23115.6211 - val_loss: 21355.6152\n",
            "Epoch 881/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23112.3398 - val_loss: 21355.2930\n",
            "Epoch 882/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23108.9473 - val_loss: 21354.8926\n",
            "Epoch 883/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 23105.7188 - val_loss: 21353.9980\n",
            "Epoch 884/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23102.5391 - val_loss: 21353.2715\n",
            "Epoch 885/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 23099.3496 - val_loss: 21352.6445\n",
            "Epoch 886/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 23096.1309 - val_loss: 21351.9297\n",
            "Epoch 887/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 23092.8613 - val_loss: 21350.6934\n",
            "Epoch 888/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23089.7129 - val_loss: 21350.1426\n",
            "Epoch 889/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 23086.5664 - val_loss: 21349.5371\n",
            "Epoch 890/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 23083.4902 - val_loss: 21348.9844\n",
            "Epoch 891/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 23080.2891 - val_loss: 21348.6465\n",
            "Epoch 892/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 23077.0020 - val_loss: 21347.3477\n",
            "Epoch 893/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23073.6855 - val_loss: 21346.9277\n",
            "Epoch 894/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23070.2422 - val_loss: 21347.7715\n",
            "Epoch 895/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 23066.8438 - val_loss: 21347.6152\n",
            "Epoch 896/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 23063.6875 - val_loss: 21347.0000\n",
            "Epoch 897/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 23060.5078 - val_loss: 21345.4746\n",
            "Epoch 898/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23057.3477 - val_loss: 21344.3027\n",
            "Epoch 899/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23054.1426 - val_loss: 21343.5977\n",
            "Epoch 900/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 23050.9082 - val_loss: 21342.9609\n",
            "Epoch 901/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 23047.6523 - val_loss: 21341.7949\n",
            "Epoch 902/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23044.4004 - val_loss: 21341.1445\n",
            "Epoch 903/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 23041.2598 - val_loss: 21340.5332\n",
            "Epoch 904/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 23038.1348 - val_loss: 21340.1016\n",
            "Epoch 905/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 23034.8965 - val_loss: 21338.8066\n",
            "Epoch 906/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23031.6914 - val_loss: 21337.6797\n",
            "Epoch 907/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23028.5293 - val_loss: 21336.9180\n",
            "Epoch 908/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 23025.3359 - val_loss: 21335.7500\n",
            "Epoch 909/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23021.9941 - val_loss: 21335.1172\n",
            "Epoch 910/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 23018.6426 - val_loss: 21335.1191\n",
            "Epoch 911/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23015.2188 - val_loss: 21334.3730\n",
            "Epoch 912/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 23012.0352 - val_loss: 21333.6973\n",
            "Epoch 913/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23008.9082 - val_loss: 21333.0684\n",
            "Epoch 914/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23005.5957 - val_loss: 21333.5781\n",
            "Epoch 915/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 23002.0332 - val_loss: 21333.9473\n",
            "Epoch 916/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 22998.6484 - val_loss: 21333.1797\n",
            "Epoch 917/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 22995.2754 - val_loss: 21332.7832\n",
            "Epoch 918/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 22992.0566 - val_loss: 21332.2070\n",
            "Epoch 919/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 22988.8848 - val_loss: 21331.3789\n",
            "Epoch 920/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 22985.5527 - val_loss: 21331.3867\n",
            "Epoch 921/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 22982.2715 - val_loss: 21330.7754\n",
            "Epoch 922/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 22979.0391 - val_loss: 21329.5977\n",
            "Epoch 923/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 22975.8027 - val_loss: 21328.9297\n",
            "Epoch 924/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 22972.5801 - val_loss: 21328.1270\n",
            "Epoch 925/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 22969.3711 - val_loss: 21327.2461\n",
            "Epoch 926/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 22966.2793 - val_loss: 21326.2578\n",
            "Epoch 927/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 22963.1719 - val_loss: 21325.4316\n",
            "Epoch 928/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 22960.1094 - val_loss: 21324.4980\n",
            "Epoch 929/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 22957.0645 - val_loss: 21323.6426\n",
            "Epoch 930/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 22953.9160 - val_loss: 21322.9043\n",
            "Epoch 931/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 22950.9062 - val_loss: 21322.4238\n",
            "Epoch 932/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 22947.8008 - val_loss: 21321.9102\n",
            "Epoch 933/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 22944.6250 - val_loss: 21321.0527\n",
            "Epoch 934/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 22941.6113 - val_loss: 21319.9316\n",
            "Epoch 935/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 22938.4980 - val_loss: 21319.6582\n",
            "Epoch 936/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 22935.1797 - val_loss: 21319.7109\n",
            "Epoch 937/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 22931.7383 - val_loss: 21320.4824\n",
            "Epoch 938/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 22928.3477 - val_loss: 21319.8711\n",
            "Epoch 939/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 22925.0332 - val_loss: 21319.0781\n",
            "Epoch 940/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 22921.8086 - val_loss: 21318.3633\n",
            "Epoch 941/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 22918.6523 - val_loss: 21317.9297\n",
            "Epoch 942/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 22915.4355 - val_loss: 21316.7090\n",
            "Epoch 943/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 22912.1309 - val_loss: 21316.0273\n",
            "Epoch 944/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 22908.7188 - val_loss: 21315.6328\n",
            "Epoch 945/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 22905.5078 - val_loss: 21315.1016\n",
            "Epoch 946/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 22902.4355 - val_loss: 21314.6523\n",
            "Epoch 947/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 22899.3320 - val_loss: 21314.4219\n",
            "Epoch 948/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 22896.1680 - val_loss: 21313.8320\n",
            "Epoch 949/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 22893.0605 - val_loss: 21312.9863\n",
            "Epoch 950/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 22889.9199 - val_loss: 21312.4434\n",
            "Epoch 951/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 22886.6641 - val_loss: 21312.1367\n",
            "Epoch 952/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 22883.3418 - val_loss: 21311.7012\n",
            "Epoch 953/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 22880.0410 - val_loss: 21310.8867\n",
            "Epoch 954/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 22876.9160 - val_loss: 21310.1875\n",
            "Epoch 955/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 22873.6953 - val_loss: 21308.8965\n",
            "Epoch 956/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 22870.5684 - val_loss: 21307.9238\n",
            "Epoch 957/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 22867.3008 - val_loss: 21308.1543\n",
            "Epoch 958/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 22863.7969 - val_loss: 21308.6016\n",
            "Epoch 959/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 22860.4609 - val_loss: 21308.3340\n",
            "Epoch 960/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 22857.3105 - val_loss: 21307.9082\n",
            "Epoch 961/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 22854.2031 - val_loss: 21307.3086\n",
            "Epoch 962/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 22850.9922 - val_loss: 21307.0078\n",
            "Epoch 963/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 22847.6719 - val_loss: 21306.9980\n",
            "Epoch 964/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 22844.4199 - val_loss: 21306.2500\n",
            "Epoch 965/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 22841.3066 - val_loss: 21305.5977\n",
            "Epoch 966/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 22838.2832 - val_loss: 21305.0195\n",
            "Epoch 967/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 22835.0527 - val_loss: 21304.1133\n",
            "Epoch 968/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 22831.8262 - val_loss: 21303.5000\n",
            "Epoch 969/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 22828.6133 - val_loss: 21302.2871\n",
            "Epoch 970/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 22825.2852 - val_loss: 21301.6680\n",
            "Epoch 971/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 22821.8594 - val_loss: 21301.8027\n",
            "Epoch 972/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 22818.3633 - val_loss: 21303.1426\n",
            "Epoch 973/1000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 22814.8477 - val_loss: 21303.9121\n",
            "Epoch 974/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 22811.5625 - val_loss: 21303.5820\n",
            "Epoch 975/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 22808.4316 - val_loss: 21303.2383\n",
            "Epoch 976/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 22805.1328 - val_loss: 21303.2891\n",
            "Epoch 977/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 22801.9004 - val_loss: 21302.7559\n",
            "Epoch 978/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 22798.7441 - val_loss: 21302.5273\n",
            "Epoch 979/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 22795.6152 - val_loss: 21301.9883\n",
            "Epoch 980/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 22792.5098 - val_loss: 21301.3340\n",
            "Epoch 981/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 22789.4121 - val_loss: 21300.6621\n",
            "Epoch 982/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 22786.3223 - val_loss: 21299.7188\n",
            "Epoch 983/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 22783.0684 - val_loss: 21297.9512\n",
            "Epoch 984/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 22779.8379 - val_loss: 21297.0430\n",
            "Epoch 985/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 22776.7812 - val_loss: 21296.3086\n",
            "Epoch 986/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 22773.8477 - val_loss: 21295.4727\n",
            "Epoch 987/1000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 22770.8164 - val_loss: 21295.0176\n",
            "Epoch 988/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 22767.7949 - val_loss: 21294.3516\n",
            "Epoch 989/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 22764.7109 - val_loss: 21293.9023\n",
            "Epoch 990/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 22761.5703 - val_loss: 21292.8848\n",
            "Epoch 991/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 22758.4551 - val_loss: 21292.4629\n",
            "Epoch 992/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 22755.3379 - val_loss: 21291.5254\n",
            "Epoch 993/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 22752.2812 - val_loss: 21290.9434\n",
            "Epoch 994/1000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 22749.1289 - val_loss: 21290.2383\n",
            "Epoch 995/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 22746.0039 - val_loss: 21290.1270\n",
            "Epoch 996/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 22742.8633 - val_loss: 21289.8047\n",
            "Epoch 997/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 22739.6934 - val_loss: 21289.1426\n",
            "Epoch 998/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 22736.4824 - val_loss: 21288.9922\n",
            "Epoch 999/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 22733.1875 - val_loss: 21289.1953\n",
            "Epoch 1000/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 22729.8379 - val_loss: 21288.5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_slp = model_slp.evaluate(x_test_scaled, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_gbkWVYJu2w",
        "outputId": "6fae46ee-0e88-444b-cee7-64aa6598b2a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 5ms/step - loss: 21288.5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('mean squared error:', loss_slp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smxNmAK5KwLv",
        "outputId": "894a3905-51a7-48eb-98cf-d4555dffa351"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean squared error: 21288.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multi-layer keras"
      ],
      "metadata": {
        "id": "D8nKpegOL-zh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_mlp = Sequential()\n",
        "\n",
        "# add the layer\n",
        "\n",
        "model_mlp.add(Dense(50, activation='relu', input_shape=x_train.shape[1:]))\n",
        "model_mlp.add(Dense(50, activation='relu'))\n",
        "model_mlp.add(Dense(1))"
      ],
      "metadata": {
        "id": "_5YeqlemK1gu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compile the model\n",
        "model_mlp.compile(optimizer='adam',\n",
        "              loss='mean_squared_error')"
      ],
      "metadata": {
        "id": "3mxqfaExNAn3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_mlp = model_mlp.fit(x_train_scaled, y_train, epochs=1000, batch_size= 32,\n",
        "              validation_data=(x_test_scaled, y_test), verbose = 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0HULJxQZNJqk",
        "outputId": "ffea7df5-0143-4aa0-ebdd-148fd09d68d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "12/12 [==============================] - 3s 38ms/step - loss: 29630.7402 - val_loss: 26344.6855\n",
            "Epoch 2/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 29390.0332 - val_loss: 26109.0312\n",
            "Epoch 3/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 29122.5391 - val_loss: 25808.8457\n",
            "Epoch 4/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 28753.6523 - val_loss: 25392.3008\n",
            "Epoch 5/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 28254.5078 - val_loss: 24830.2891\n",
            "Epoch 6/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 27583.5527 - val_loss: 24085.0000\n",
            "Epoch 7/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 26696.6348 - val_loss: 23103.0801\n",
            "Epoch 8/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 25539.1680 - val_loss: 21886.7422\n",
            "Epoch 9/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 24105.9414 - val_loss: 20492.3457\n",
            "Epoch 10/1000\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 22602.0488 - val_loss: 18923.0840\n",
            "Epoch 11/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 20789.2207 - val_loss: 17166.1328\n",
            "Epoch 12/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 18886.4980 - val_loss: 15195.7041\n",
            "Epoch 13/1000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 16710.4570 - val_loss: 13159.7441\n",
            "Epoch 14/1000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 14579.2744 - val_loss: 11131.0566\n",
            "Epoch 15/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 12447.8438 - val_loss: 9155.1113\n",
            "Epoch 16/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 10416.8037 - val_loss: 7614.4707\n",
            "Epoch 17/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 8877.8809 - val_loss: 6392.2305\n",
            "Epoch 18/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 7654.8569 - val_loss: 5505.9331\n",
            "Epoch 19/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 6792.4023 - val_loss: 4779.7754\n",
            "Epoch 20/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 6077.8745 - val_loss: 4377.1123\n",
            "Epoch 21/1000\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 5610.6592 - val_loss: 4133.6587\n",
            "Epoch 22/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 5300.4956 - val_loss: 4013.9478\n",
            "Epoch 23/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 5021.8184 - val_loss: 3915.0322\n",
            "Epoch 24/1000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 4808.5767 - val_loss: 3836.2917\n",
            "Epoch 25/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 4604.0298 - val_loss: 3772.6521\n",
            "Epoch 26/1000\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 4435.8975 - val_loss: 3724.9758\n",
            "Epoch 27/1000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 4286.5605 - val_loss: 3679.9558\n",
            "Epoch 28/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 4142.5205 - val_loss: 3646.3364\n",
            "Epoch 29/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 4010.8213 - val_loss: 3647.9111\n",
            "Epoch 30/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 3916.5410 - val_loss: 3626.0857\n",
            "Epoch 31/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 3840.1685 - val_loss: 3598.0884\n",
            "Epoch 32/1000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 3760.1350 - val_loss: 3568.7756\n",
            "Epoch 33/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3698.8789 - val_loss: 3547.5481\n",
            "Epoch 34/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 3646.1445 - val_loss: 3535.7612\n",
            "Epoch 35/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3600.2490 - val_loss: 3500.0737\n",
            "Epoch 36/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3558.2078 - val_loss: 3473.6538\n",
            "Epoch 37/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3508.8467 - val_loss: 3450.5527\n",
            "Epoch 38/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3466.6023 - val_loss: 3425.5022\n",
            "Epoch 39/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3432.2561 - val_loss: 3405.5168\n",
            "Epoch 40/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3413.5486 - val_loss: 3394.7866\n",
            "Epoch 41/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3371.9114 - val_loss: 3346.1008\n",
            "Epoch 42/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3322.6218 - val_loss: 3317.1746\n",
            "Epoch 43/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 3293.0784 - val_loss: 3308.2202\n",
            "Epoch 44/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3257.9639 - val_loss: 3279.8999\n",
            "Epoch 45/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3223.8381 - val_loss: 3248.6565\n",
            "Epoch 46/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3216.6580 - val_loss: 3241.9546\n",
            "Epoch 47/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 3188.2007 - val_loss: 3227.8765\n",
            "Epoch 48/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3154.2341 - val_loss: 3217.2754\n",
            "Epoch 49/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3127.9751 - val_loss: 3227.5735\n",
            "Epoch 50/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3117.0764 - val_loss: 3214.4031\n",
            "Epoch 51/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3100.6975 - val_loss: 3190.2722\n",
            "Epoch 52/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3084.1218 - val_loss: 3146.4246\n",
            "Epoch 53/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3063.0266 - val_loss: 3121.0435\n",
            "Epoch 54/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3047.3972 - val_loss: 3109.5825\n",
            "Epoch 55/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3037.6541 - val_loss: 3154.2876\n",
            "Epoch 56/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3043.7422 - val_loss: 3165.1250\n",
            "Epoch 57/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3033.7412 - val_loss: 3145.0344\n",
            "Epoch 58/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3009.5071 - val_loss: 3106.2458\n",
            "Epoch 59/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2985.9978 - val_loss: 3061.7205\n",
            "Epoch 60/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2990.7097 - val_loss: 3050.5112\n",
            "Epoch 61/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2997.9358 - val_loss: 3034.0142\n",
            "Epoch 62/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2977.9150 - val_loss: 3010.5283\n",
            "Epoch 63/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2959.5046 - val_loss: 3001.5408\n",
            "Epoch 64/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2925.6794 - val_loss: 2997.9277\n",
            "Epoch 65/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2924.7175 - val_loss: 3007.9648\n",
            "Epoch 66/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2916.4973 - val_loss: 3003.2620\n",
            "Epoch 67/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2907.0256 - val_loss: 2985.1072\n",
            "Epoch 68/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2903.4968 - val_loss: 2984.9128\n",
            "Epoch 69/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2883.4463 - val_loss: 2993.7747\n",
            "Epoch 70/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2879.5583 - val_loss: 3003.4727\n",
            "Epoch 71/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2886.5891 - val_loss: 3106.0579\n",
            "Epoch 72/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2908.5149 - val_loss: 3110.3132\n",
            "Epoch 73/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2902.7507 - val_loss: 3091.4546\n",
            "Epoch 74/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2876.4509 - val_loss: 3045.7388\n",
            "Epoch 75/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2844.7629 - val_loss: 3006.4280\n",
            "Epoch 76/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2855.8132 - val_loss: 3005.7444\n",
            "Epoch 77/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2847.0500 - val_loss: 2998.4839\n",
            "Epoch 78/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2836.7336 - val_loss: 2992.9673\n",
            "Epoch 79/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2837.2620 - val_loss: 3018.8503\n",
            "Epoch 80/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2838.1167 - val_loss: 3015.6707\n",
            "Epoch 81/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2837.1882 - val_loss: 3013.1448\n",
            "Epoch 82/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2833.5115 - val_loss: 3010.6685\n",
            "Epoch 83/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2817.8633 - val_loss: 2986.1997\n",
            "Epoch 84/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2809.1782 - val_loss: 2963.9353\n",
            "Epoch 85/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2800.1384 - val_loss: 2940.7427\n",
            "Epoch 86/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2791.2852 - val_loss: 2948.2285\n",
            "Epoch 87/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2793.5459 - val_loss: 2950.2437\n",
            "Epoch 88/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2806.5625 - val_loss: 2977.5586\n",
            "Epoch 89/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2790.1138 - val_loss: 2972.8459\n",
            "Epoch 90/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2778.1724 - val_loss: 2952.5256\n",
            "Epoch 91/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2772.9978 - val_loss: 2939.9766\n",
            "Epoch 92/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 2778.4333 - val_loss: 2951.6057\n",
            "Epoch 93/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 2776.8137 - val_loss: 2970.1777\n",
            "Epoch 94/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2768.2859 - val_loss: 2971.6709\n",
            "Epoch 95/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 2777.1326 - val_loss: 2997.6963\n",
            "Epoch 96/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2776.8777 - val_loss: 2981.5898\n",
            "Epoch 97/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2770.8623 - val_loss: 2964.4407\n",
            "Epoch 98/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2770.4482 - val_loss: 2970.7546\n",
            "Epoch 99/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2767.1147 - val_loss: 2956.8142\n",
            "Epoch 100/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2754.4185 - val_loss: 2939.7458\n",
            "Epoch 101/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2749.0718 - val_loss: 2923.1426\n",
            "Epoch 102/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2739.9302 - val_loss: 2926.8511\n",
            "Epoch 103/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2739.2849 - val_loss: 2927.5271\n",
            "Epoch 104/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2742.7637 - val_loss: 2926.1990\n",
            "Epoch 105/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 2742.2251 - val_loss: 2908.2300\n",
            "Epoch 106/1000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2732.1602 - val_loss: 2904.7791\n",
            "Epoch 107/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 2733.4968 - val_loss: 2909.5022\n",
            "Epoch 108/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 2749.0220 - val_loss: 2936.2900\n",
            "Epoch 109/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2775.7637 - val_loss: 2928.9841\n",
            "Epoch 110/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2764.7612 - val_loss: 2905.3193\n",
            "Epoch 111/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 2740.3740 - val_loss: 2909.0881\n",
            "Epoch 112/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 2728.0632 - val_loss: 2909.0337\n",
            "Epoch 113/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2711.5713 - val_loss: 2911.1001\n",
            "Epoch 114/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2727.5115 - val_loss: 2901.8977\n",
            "Epoch 115/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 2729.4260 - val_loss: 2884.5054\n",
            "Epoch 116/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2717.5854 - val_loss: 2869.3804\n",
            "Epoch 117/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 2713.1638 - val_loss: 2850.4919\n",
            "Epoch 118/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2712.2407 - val_loss: 2853.8860\n",
            "Epoch 119/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2705.6692 - val_loss: 2861.7371\n",
            "Epoch 120/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2699.6128 - val_loss: 2855.5010\n",
            "Epoch 121/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2698.0637 - val_loss: 2852.2832\n",
            "Epoch 122/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2694.8311 - val_loss: 2852.5439\n",
            "Epoch 123/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2690.8396 - val_loss: 2854.1443\n",
            "Epoch 124/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2690.9021 - val_loss: 2849.1260\n",
            "Epoch 125/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2698.8367 - val_loss: 2834.1416\n",
            "Epoch 126/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2688.2388 - val_loss: 2832.9900\n",
            "Epoch 127/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2685.3074 - val_loss: 2837.4988\n",
            "Epoch 128/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2683.0796 - val_loss: 2842.8359\n",
            "Epoch 129/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2689.9553 - val_loss: 2848.3003\n",
            "Epoch 130/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2680.6660 - val_loss: 2832.4119\n",
            "Epoch 131/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2680.5725 - val_loss: 2841.4492\n",
            "Epoch 132/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2679.7590 - val_loss: 2841.7190\n",
            "Epoch 133/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2675.2852 - val_loss: 2838.7434\n",
            "Epoch 134/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2672.0210 - val_loss: 2835.2883\n",
            "Epoch 135/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2669.8940 - val_loss: 2856.9700\n",
            "Epoch 136/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2675.8794 - val_loss: 2858.7905\n",
            "Epoch 137/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2675.2695 - val_loss: 2866.1270\n",
            "Epoch 138/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2679.3711 - val_loss: 2874.7251\n",
            "Epoch 139/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2679.9980 - val_loss: 2876.9670\n",
            "Epoch 140/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2689.6292 - val_loss: 2869.5276\n",
            "Epoch 141/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2674.2439 - val_loss: 2851.5066\n",
            "Epoch 142/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2669.7078 - val_loss: 2845.7427\n",
            "Epoch 143/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2681.6299 - val_loss: 2833.4126\n",
            "Epoch 144/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2657.5642 - val_loss: 2799.8481\n",
            "Epoch 145/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2644.7375 - val_loss: 2804.1531\n",
            "Epoch 146/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2648.1035 - val_loss: 2794.3201\n",
            "Epoch 147/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2649.6409 - val_loss: 2779.2136\n",
            "Epoch 148/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2640.3618 - val_loss: 2788.2078\n",
            "Epoch 149/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2642.5977 - val_loss: 2787.9426\n",
            "Epoch 150/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2644.8787 - val_loss: 2796.6484\n",
            "Epoch 151/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2636.5422 - val_loss: 2800.4165\n",
            "Epoch 152/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2634.2668 - val_loss: 2826.7239\n",
            "Epoch 153/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2648.6853 - val_loss: 2829.0684\n",
            "Epoch 154/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2646.7869 - val_loss: 2817.5747\n",
            "Epoch 155/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 2630.5300 - val_loss: 2791.0479\n",
            "Epoch 156/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2638.5645 - val_loss: 2781.6165\n",
            "Epoch 157/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2659.3313 - val_loss: 2792.1794\n",
            "Epoch 158/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2665.8730 - val_loss: 2790.1543\n",
            "Epoch 159/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2645.1248 - val_loss: 2777.3213\n",
            "Epoch 160/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2636.1035 - val_loss: 2755.9065\n",
            "Epoch 161/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2627.4346 - val_loss: 2745.4502\n",
            "Epoch 162/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2625.9565 - val_loss: 2751.7234\n",
            "Epoch 163/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2626.4019 - val_loss: 2754.6492\n",
            "Epoch 164/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2623.1497 - val_loss: 2758.0527\n",
            "Epoch 165/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2622.4534 - val_loss: 2760.1753\n",
            "Epoch 166/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2619.3335 - val_loss: 2760.0205\n",
            "Epoch 167/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2618.9924 - val_loss: 2752.6958\n",
            "Epoch 168/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2615.0576 - val_loss: 2750.7134\n",
            "Epoch 169/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2611.5303 - val_loss: 2748.3533\n",
            "Epoch 170/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2617.3008 - val_loss: 2732.2551\n",
            "Epoch 171/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2610.1956 - val_loss: 2729.2148\n",
            "Epoch 172/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2610.5544 - val_loss: 2731.4092\n",
            "Epoch 173/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2604.3860 - val_loss: 2748.0193\n",
            "Epoch 174/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2607.4707 - val_loss: 2758.1548\n",
            "Epoch 175/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2602.6194 - val_loss: 2767.2056\n",
            "Epoch 176/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2601.7529 - val_loss: 2773.1189\n",
            "Epoch 177/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2605.5483 - val_loss: 2768.1074\n",
            "Epoch 178/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2602.7156 - val_loss: 2760.6592\n",
            "Epoch 179/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2610.0557 - val_loss: 2727.6321\n",
            "Epoch 180/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2610.3203 - val_loss: 2718.3069\n",
            "Epoch 181/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2599.6172 - val_loss: 2713.5310\n",
            "Epoch 182/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2596.7661 - val_loss: 2697.9802\n",
            "Epoch 183/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2605.9456 - val_loss: 2702.7903\n",
            "Epoch 184/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2598.9802 - val_loss: 2706.3147\n",
            "Epoch 185/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2591.7769 - val_loss: 2752.8328\n",
            "Epoch 186/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2592.6562 - val_loss: 2759.7551\n",
            "Epoch 187/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2586.1626 - val_loss: 2748.6824\n",
            "Epoch 188/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2580.7927 - val_loss: 2750.8516\n",
            "Epoch 189/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2583.7786 - val_loss: 2744.1501\n",
            "Epoch 190/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2579.8545 - val_loss: 2737.0022\n",
            "Epoch 191/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2574.9443 - val_loss: 2732.1023\n",
            "Epoch 192/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2569.3979 - val_loss: 2720.7529\n",
            "Epoch 193/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2576.0432 - val_loss: 2710.0427\n",
            "Epoch 194/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2573.7043 - val_loss: 2695.1785\n",
            "Epoch 195/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2570.4370 - val_loss: 2692.7524\n",
            "Epoch 196/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2566.2520 - val_loss: 2718.5127\n",
            "Epoch 197/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2617.1145 - val_loss: 2735.8979\n",
            "Epoch 198/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2612.6646 - val_loss: 2717.8047\n",
            "Epoch 199/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2581.6179 - val_loss: 2709.3779\n",
            "Epoch 200/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2568.0291 - val_loss: 2703.0090\n",
            "Epoch 201/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2560.8596 - val_loss: 2698.1895\n",
            "Epoch 202/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2560.0552 - val_loss: 2705.8096\n",
            "Epoch 203/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2554.6897 - val_loss: 2713.0139\n",
            "Epoch 204/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2550.6743 - val_loss: 2725.4231\n",
            "Epoch 205/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2573.6167 - val_loss: 2745.1125\n",
            "Epoch 206/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2561.6301 - val_loss: 2727.8162\n",
            "Epoch 207/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2552.5281 - val_loss: 2725.6152\n",
            "Epoch 208/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2551.0479 - val_loss: 2724.2478\n",
            "Epoch 209/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2548.3740 - val_loss: 2720.8035\n",
            "Epoch 210/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2546.6531 - val_loss: 2746.9304\n",
            "Epoch 211/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2548.1904 - val_loss: 2741.6731\n",
            "Epoch 212/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2554.4761 - val_loss: 2718.5061\n",
            "Epoch 213/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2550.6943 - val_loss: 2701.0430\n",
            "Epoch 214/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2551.7588 - val_loss: 2698.0806\n",
            "Epoch 215/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2548.3486 - val_loss: 2696.7551\n",
            "Epoch 216/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2543.3420 - val_loss: 2700.2886\n",
            "Epoch 217/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2548.8040 - val_loss: 2716.6611\n",
            "Epoch 218/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2543.5823 - val_loss: 2716.7271\n",
            "Epoch 219/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2534.3623 - val_loss: 2742.2585\n",
            "Epoch 220/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2542.4417 - val_loss: 2749.6516\n",
            "Epoch 221/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2543.7354 - val_loss: 2755.6069\n",
            "Epoch 222/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2541.0959 - val_loss: 2760.6790\n",
            "Epoch 223/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2538.2732 - val_loss: 2754.7375\n",
            "Epoch 224/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2558.9124 - val_loss: 2774.9531\n",
            "Epoch 225/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2579.2708 - val_loss: 2762.9060\n",
            "Epoch 226/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2570.5068 - val_loss: 2762.6609\n",
            "Epoch 227/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2557.5073 - val_loss: 2748.1443\n",
            "Epoch 228/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2541.6162 - val_loss: 2741.4189\n",
            "Epoch 229/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2541.9900 - val_loss: 2732.0732\n",
            "Epoch 230/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2537.4316 - val_loss: 2727.5586\n",
            "Epoch 231/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2526.6353 - val_loss: 2726.2546\n",
            "Epoch 232/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2534.4805 - val_loss: 2732.4746\n",
            "Epoch 233/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2537.6702 - val_loss: 2727.1365\n",
            "Epoch 234/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2537.2180 - val_loss: 2716.6238\n",
            "Epoch 235/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2524.9412 - val_loss: 2730.6287\n",
            "Epoch 236/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2529.0374 - val_loss: 2738.8386\n",
            "Epoch 237/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2524.1030 - val_loss: 2744.5952\n",
            "Epoch 238/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2530.1106 - val_loss: 2772.1597\n",
            "Epoch 239/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2526.7034 - val_loss: 2767.5728\n",
            "Epoch 240/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2519.8533 - val_loss: 2746.6003\n",
            "Epoch 241/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2506.1836 - val_loss: 2742.8696\n",
            "Epoch 242/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2518.2969 - val_loss: 2754.6956\n",
            "Epoch 243/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2509.3928 - val_loss: 2741.0713\n",
            "Epoch 244/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2511.5061 - val_loss: 2729.0266\n",
            "Epoch 245/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2509.0969 - val_loss: 2729.7566\n",
            "Epoch 246/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2506.3223 - val_loss: 2722.8792\n",
            "Epoch 247/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2490.4604 - val_loss: 2738.2368\n",
            "Epoch 248/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2505.9622 - val_loss: 2737.0566\n",
            "Epoch 249/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2509.2754 - val_loss: 2731.8364\n",
            "Epoch 250/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 2498.1118 - val_loss: 2735.4746\n",
            "Epoch 251/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2495.3638 - val_loss: 2726.5859\n",
            "Epoch 252/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 2495.5496 - val_loss: 2729.8550\n",
            "Epoch 253/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2492.2888 - val_loss: 2705.9097\n",
            "Epoch 254/1000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2491.9456 - val_loss: 2695.1724\n",
            "Epoch 255/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 2492.4094 - val_loss: 2684.9143\n",
            "Epoch 256/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2493.3403 - val_loss: 2688.5935\n",
            "Epoch 257/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2485.1091 - val_loss: 2686.7058\n",
            "Epoch 258/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 2488.7463 - val_loss: 2686.2063\n",
            "Epoch 259/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2484.6028 - val_loss: 2697.7556\n",
            "Epoch 260/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2485.6873 - val_loss: 2706.8359\n",
            "Epoch 261/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2490.0918 - val_loss: 2710.4092\n",
            "Epoch 262/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 2483.9670 - val_loss: 2709.1409\n",
            "Epoch 263/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 2491.1777 - val_loss: 2713.2703\n",
            "Epoch 264/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2504.9246 - val_loss: 2724.8984\n",
            "Epoch 265/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 2497.9944 - val_loss: 2714.1167\n",
            "Epoch 266/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 2486.2876 - val_loss: 2705.5574\n",
            "Epoch 267/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 2492.9822 - val_loss: 2702.4858\n",
            "Epoch 268/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 2486.4265 - val_loss: 2696.3147\n",
            "Epoch 269/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 2479.4019 - val_loss: 2700.1597\n",
            "Epoch 270/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2473.1555 - val_loss: 2698.2100\n",
            "Epoch 271/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 2467.0210 - val_loss: 2694.4333\n",
            "Epoch 272/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 2464.5474 - val_loss: 2706.9229\n",
            "Epoch 273/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 2476.2539 - val_loss: 2705.9431\n",
            "Epoch 274/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2480.3120 - val_loss: 2689.5688\n",
            "Epoch 275/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2467.6204 - val_loss: 2682.1980\n",
            "Epoch 276/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2462.4905 - val_loss: 2695.4866\n",
            "Epoch 277/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 2463.6753 - val_loss: 2700.8865\n",
            "Epoch 278/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 2468.8701 - val_loss: 2742.9133\n",
            "Epoch 279/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2476.0854 - val_loss: 2730.4109\n",
            "Epoch 280/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2471.2573 - val_loss: 2732.1633\n",
            "Epoch 281/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2472.9099 - val_loss: 2738.2466\n",
            "Epoch 282/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2467.1143 - val_loss: 2721.1123\n",
            "Epoch 283/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2460.7058 - val_loss: 2710.9800\n",
            "Epoch 284/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2463.8833 - val_loss: 2702.1724\n",
            "Epoch 285/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2456.8921 - val_loss: 2692.3694\n",
            "Epoch 286/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2451.3630 - val_loss: 2701.0203\n",
            "Epoch 287/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2447.3936 - val_loss: 2704.2969\n",
            "Epoch 288/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2446.8218 - val_loss: 2737.8740\n",
            "Epoch 289/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2453.3806 - val_loss: 2763.6636\n",
            "Epoch 290/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2464.9644 - val_loss: 2762.8381\n",
            "Epoch 291/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2442.4424 - val_loss: 2687.1404\n",
            "Epoch 292/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2448.8408 - val_loss: 2665.1279\n",
            "Epoch 293/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2441.9304 - val_loss: 2659.9270\n",
            "Epoch 294/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2460.5974 - val_loss: 2658.0269\n",
            "Epoch 295/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2442.0442 - val_loss: 2661.2578\n",
            "Epoch 296/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 2442.0037 - val_loss: 2665.5437\n",
            "Epoch 297/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2449.3088 - val_loss: 2678.5190\n",
            "Epoch 298/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2458.0437 - val_loss: 2711.8435\n",
            "Epoch 299/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2452.8369 - val_loss: 2705.7559\n",
            "Epoch 300/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2442.6814 - val_loss: 2688.9966\n",
            "Epoch 301/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2438.8379 - val_loss: 2680.4143\n",
            "Epoch 302/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2434.9321 - val_loss: 2675.4900\n",
            "Epoch 303/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2433.5920 - val_loss: 2690.8567\n",
            "Epoch 304/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2440.5391 - val_loss: 2696.8704\n",
            "Epoch 305/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2433.4365 - val_loss: 2692.6790\n",
            "Epoch 306/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2432.8501 - val_loss: 2704.6804\n",
            "Epoch 307/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2460.9275 - val_loss: 2730.1057\n",
            "Epoch 308/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2463.3933 - val_loss: 2727.3840\n",
            "Epoch 309/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2445.3872 - val_loss: 2695.5312\n",
            "Epoch 310/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2428.5425 - val_loss: 2684.3848\n",
            "Epoch 311/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2421.2214 - val_loss: 2695.3994\n",
            "Epoch 312/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2425.5608 - val_loss: 2687.8689\n",
            "Epoch 313/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2412.2913 - val_loss: 2698.7292\n",
            "Epoch 314/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2416.0930 - val_loss: 2702.2981\n",
            "Epoch 315/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2415.7461 - val_loss: 2717.1689\n",
            "Epoch 316/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2422.0215 - val_loss: 2724.4741\n",
            "Epoch 317/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2416.1819 - val_loss: 2721.0901\n",
            "Epoch 318/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2409.1057 - val_loss: 2706.9053\n",
            "Epoch 319/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2404.2698 - val_loss: 2685.4072\n",
            "Epoch 320/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2420.5100 - val_loss: 2688.5266\n",
            "Epoch 321/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2450.1960 - val_loss: 2680.7102\n",
            "Epoch 322/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2408.3721 - val_loss: 2666.8579\n",
            "Epoch 323/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2398.5442 - val_loss: 2678.0134\n",
            "Epoch 324/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2399.3315 - val_loss: 2695.8994\n",
            "Epoch 325/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2412.7432 - val_loss: 2760.0071\n",
            "Epoch 326/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2445.9565 - val_loss: 2780.4080\n",
            "Epoch 327/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2450.6638 - val_loss: 2760.1821\n",
            "Epoch 328/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2424.9351 - val_loss: 2724.7383\n",
            "Epoch 329/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2404.4883 - val_loss: 2709.0908\n",
            "Epoch 330/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2401.0513 - val_loss: 2701.0820\n",
            "Epoch 331/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2417.5273 - val_loss: 2691.3220\n",
            "Epoch 332/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2402.9006 - val_loss: 2676.2839\n",
            "Epoch 333/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2449.8115 - val_loss: 2685.3003\n",
            "Epoch 334/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2475.3386 - val_loss: 2680.2971\n",
            "Epoch 335/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2441.2603 - val_loss: 2639.2861\n",
            "Epoch 336/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2417.3687 - val_loss: 2630.8992\n",
            "Epoch 337/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2405.8652 - val_loss: 2644.4268\n",
            "Epoch 338/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2389.4517 - val_loss: 2656.0413\n",
            "Epoch 339/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2396.7712 - val_loss: 2693.6946\n",
            "Epoch 340/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2395.3796 - val_loss: 2709.4158\n",
            "Epoch 341/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2396.7334 - val_loss: 2695.8259\n",
            "Epoch 342/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2397.1707 - val_loss: 2704.7781\n",
            "Epoch 343/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2397.7046 - val_loss: 2696.1819\n",
            "Epoch 344/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 2378.5674 - val_loss: 2685.6614\n",
            "Epoch 345/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2364.4624 - val_loss: 2678.7104\n",
            "Epoch 346/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2363.5359 - val_loss: 2675.6663\n",
            "Epoch 347/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2362.0776 - val_loss: 2675.6899\n",
            "Epoch 348/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2362.9082 - val_loss: 2677.3472\n",
            "Epoch 349/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2356.3596 - val_loss: 2689.9587\n",
            "Epoch 350/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 2362.7380 - val_loss: 2690.3748\n",
            "Epoch 351/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2369.0796 - val_loss: 2679.0034\n",
            "Epoch 352/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2373.5679 - val_loss: 2677.4941\n",
            "Epoch 353/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 2363.1997 - val_loss: 2670.7822\n",
            "Epoch 354/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 2356.2959 - val_loss: 2683.5334\n",
            "Epoch 355/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2361.9609 - val_loss: 2707.7678\n",
            "Epoch 356/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2361.3416 - val_loss: 2701.7498\n",
            "Epoch 357/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2375.5234 - val_loss: 2713.8574\n",
            "Epoch 358/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2387.8772 - val_loss: 2692.8750\n",
            "Epoch 359/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2374.5276 - val_loss: 2674.9360\n",
            "Epoch 360/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 2352.6785 - val_loss: 2667.3154\n",
            "Epoch 361/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 2347.3823 - val_loss: 2664.7471\n",
            "Epoch 362/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2346.1650 - val_loss: 2669.7234\n",
            "Epoch 363/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2338.8616 - val_loss: 2658.8486\n",
            "Epoch 364/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 2351.2793 - val_loss: 2663.2166\n",
            "Epoch 365/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 2342.0159 - val_loss: 2658.9365\n",
            "Epoch 366/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2347.0312 - val_loss: 2667.2454\n",
            "Epoch 367/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 2381.5625 - val_loss: 2685.6179\n",
            "Epoch 368/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 2395.1543 - val_loss: 2674.1372\n",
            "Epoch 369/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 2371.7224 - val_loss: 2653.8516\n",
            "Epoch 370/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 2349.3315 - val_loss: 2634.8457\n",
            "Epoch 371/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2339.6069 - val_loss: 2659.3494\n",
            "Epoch 372/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2357.0486 - val_loss: 2699.9758\n",
            "Epoch 373/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 2345.1492 - val_loss: 2703.9338\n",
            "Epoch 374/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 2339.5120 - val_loss: 2710.1272\n",
            "Epoch 375/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2337.2129 - val_loss: 2720.1145\n",
            "Epoch 376/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2332.3076 - val_loss: 2719.3276\n",
            "Epoch 377/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2326.6887 - val_loss: 2713.2383\n",
            "Epoch 378/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2328.4417 - val_loss: 2716.0015\n",
            "Epoch 379/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2327.6538 - val_loss: 2726.8423\n",
            "Epoch 380/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2323.5698 - val_loss: 2721.4172\n",
            "Epoch 381/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2320.6470 - val_loss: 2718.0283\n",
            "Epoch 382/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2316.2773 - val_loss: 2720.5796\n",
            "Epoch 383/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2313.4192 - val_loss: 2715.9961\n",
            "Epoch 384/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2311.7896 - val_loss: 2740.7451\n",
            "Epoch 385/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2317.4961 - val_loss: 2751.6248\n",
            "Epoch 386/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2319.0559 - val_loss: 2747.3623\n",
            "Epoch 387/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2312.7747 - val_loss: 2734.3970\n",
            "Epoch 388/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2309.7268 - val_loss: 2721.3831\n",
            "Epoch 389/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2306.3154 - val_loss: 2708.6965\n",
            "Epoch 390/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2323.4531 - val_loss: 2712.8689\n",
            "Epoch 391/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2331.0537 - val_loss: 2702.2219\n",
            "Epoch 392/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 2314.3589 - val_loss: 2689.1411\n",
            "Epoch 393/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 2301.8250 - val_loss: 2690.9126\n",
            "Epoch 394/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2299.1499 - val_loss: 2716.6292\n",
            "Epoch 395/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2308.8657 - val_loss: 2727.5579\n",
            "Epoch 396/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2306.1697 - val_loss: 2714.7991\n",
            "Epoch 397/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2300.8628 - val_loss: 2701.2134\n",
            "Epoch 398/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2292.8469 - val_loss: 2694.4626\n",
            "Epoch 399/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2290.2966 - val_loss: 2733.1609\n",
            "Epoch 400/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 2307.3127 - val_loss: 2785.8269\n",
            "Epoch 401/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 2365.6892 - val_loss: 2823.7810\n",
            "Epoch 402/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2357.1140 - val_loss: 2773.1804\n",
            "Epoch 403/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 2317.8877 - val_loss: 2738.1799\n",
            "Epoch 404/1000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2284.3406 - val_loss: 2724.2905\n",
            "Epoch 405/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 2295.0659 - val_loss: 2711.3147\n",
            "Epoch 406/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 2284.4624 - val_loss: 2682.1353\n",
            "Epoch 407/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2284.9036 - val_loss: 2644.5869\n",
            "Epoch 408/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2319.4202 - val_loss: 2742.0618\n",
            "Epoch 409/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 2373.3071 - val_loss: 2754.1033\n",
            "Epoch 410/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 2330.2007 - val_loss: 2721.3357\n",
            "Epoch 411/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2301.1917 - val_loss: 2688.5208\n",
            "Epoch 412/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2285.3870 - val_loss: 2700.4871\n",
            "Epoch 413/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2281.5164 - val_loss: 2700.0815\n",
            "Epoch 414/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2284.0437 - val_loss: 2693.7083\n",
            "Epoch 415/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2285.0718 - val_loss: 2679.3838\n",
            "Epoch 416/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 2277.9377 - val_loss: 2672.8953\n",
            "Epoch 417/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2281.2805 - val_loss: 2702.4153\n",
            "Epoch 418/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2274.8477 - val_loss: 2695.9109\n",
            "Epoch 419/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2272.8953 - val_loss: 2673.6123\n",
            "Epoch 420/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 2271.0930 - val_loss: 2657.8428\n",
            "Epoch 421/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2269.4961 - val_loss: 2653.7314\n",
            "Epoch 422/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2271.4634 - val_loss: 2679.9951\n",
            "Epoch 423/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 2272.2432 - val_loss: 2659.6196\n",
            "Epoch 424/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 2272.5425 - val_loss: 2644.9670\n",
            "Epoch 425/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 2265.6152 - val_loss: 2641.8486\n",
            "Epoch 426/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2263.0481 - val_loss: 2637.4155\n",
            "Epoch 427/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2257.6106 - val_loss: 2654.1587\n",
            "Epoch 428/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2261.3794 - val_loss: 2656.0049\n",
            "Epoch 429/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2257.8074 - val_loss: 2651.1587\n",
            "Epoch 430/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2262.1292 - val_loss: 2661.3181\n",
            "Epoch 431/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2264.7429 - val_loss: 2659.9146\n",
            "Epoch 432/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2250.0518 - val_loss: 2656.1870\n",
            "Epoch 433/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2251.6055 - val_loss: 2650.3584\n",
            "Epoch 434/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2248.6465 - val_loss: 2668.6890\n",
            "Epoch 435/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2248.8291 - val_loss: 2675.2590\n",
            "Epoch 436/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2246.8958 - val_loss: 2680.7427\n",
            "Epoch 437/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2244.7178 - val_loss: 2672.6257\n",
            "Epoch 438/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2246.0100 - val_loss: 2688.2502\n",
            "Epoch 439/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2248.4541 - val_loss: 2692.9470\n",
            "Epoch 440/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2244.4072 - val_loss: 2687.1309\n",
            "Epoch 441/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2238.0466 - val_loss: 2685.4453\n",
            "Epoch 442/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2239.4673 - val_loss: 2714.3608\n",
            "Epoch 443/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2240.7432 - val_loss: 2722.4863\n",
            "Epoch 444/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 2258.6504 - val_loss: 2713.8972\n",
            "Epoch 445/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2245.0298 - val_loss: 2702.0208\n",
            "Epoch 446/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2235.0259 - val_loss: 2713.1169\n",
            "Epoch 447/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2237.2749 - val_loss: 2710.5996\n",
            "Epoch 448/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2226.0242 - val_loss: 2708.6428\n",
            "Epoch 449/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2224.3811 - val_loss: 2721.4177\n",
            "Epoch 450/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2224.4177 - val_loss: 2720.8936\n",
            "Epoch 451/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2220.7913 - val_loss: 2718.8701\n",
            "Epoch 452/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2226.2607 - val_loss: 2731.1829\n",
            "Epoch 453/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2227.0874 - val_loss: 2709.7695\n",
            "Epoch 454/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2219.1892 - val_loss: 2701.1384\n",
            "Epoch 455/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2216.1636 - val_loss: 2704.0796\n",
            "Epoch 456/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2208.8687 - val_loss: 2701.2253\n",
            "Epoch 457/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2224.9490 - val_loss: 2709.7117\n",
            "Epoch 458/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2213.3997 - val_loss: 2694.3105\n",
            "Epoch 459/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2208.4548 - val_loss: 2690.3655\n",
            "Epoch 460/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2206.8667 - val_loss: 2708.4646\n",
            "Epoch 461/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2222.4495 - val_loss: 2714.6323\n",
            "Epoch 462/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2224.9436 - val_loss: 2702.3010\n",
            "Epoch 463/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2232.4668 - val_loss: 2702.2332\n",
            "Epoch 464/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2225.8503 - val_loss: 2683.4597\n",
            "Epoch 465/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2209.3220 - val_loss: 2673.7324\n",
            "Epoch 466/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2209.7522 - val_loss: 2661.9309\n",
            "Epoch 467/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2214.4358 - val_loss: 2652.5967\n",
            "Epoch 468/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2218.9160 - val_loss: 2645.5039\n",
            "Epoch 469/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2207.1311 - val_loss: 2646.2546\n",
            "Epoch 470/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2199.5093 - val_loss: 2673.0605\n",
            "Epoch 471/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2205.3694 - val_loss: 2695.0537\n",
            "Epoch 472/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2209.2485 - val_loss: 2686.3040\n",
            "Epoch 473/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2203.0583 - val_loss: 2696.9905\n",
            "Epoch 474/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2199.1963 - val_loss: 2716.5242\n",
            "Epoch 475/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2189.9458 - val_loss: 2699.1318\n",
            "Epoch 476/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2219.2529 - val_loss: 2731.2964\n",
            "Epoch 477/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2213.9661 - val_loss: 2712.3447\n",
            "Epoch 478/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2211.8965 - val_loss: 2700.4910\n",
            "Epoch 479/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2188.6111 - val_loss: 2702.1924\n",
            "Epoch 480/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2181.7705 - val_loss: 2730.3118\n",
            "Epoch 481/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2198.0518 - val_loss: 2725.1643\n",
            "Epoch 482/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2203.5337 - val_loss: 2705.4080\n",
            "Epoch 483/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2189.5693 - val_loss: 2703.4609\n",
            "Epoch 484/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2175.9841 - val_loss: 2699.0264\n",
            "Epoch 485/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2196.3142 - val_loss: 2730.8127\n",
            "Epoch 486/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2199.7524 - val_loss: 2729.9241\n",
            "Epoch 487/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2219.6858 - val_loss: 2772.5342\n",
            "Epoch 488/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2175.8843 - val_loss: 2716.2458\n",
            "Epoch 489/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2165.0039 - val_loss: 2700.2197\n",
            "Epoch 490/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2169.9263 - val_loss: 2692.8235\n",
            "Epoch 491/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2164.0139 - val_loss: 2686.1721\n",
            "Epoch 492/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2166.6523 - val_loss: 2683.6228\n",
            "Epoch 493/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2162.2239 - val_loss: 2674.3691\n",
            "Epoch 494/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2165.3115 - val_loss: 2685.0688\n",
            "Epoch 495/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2180.9910 - val_loss: 2678.1917\n",
            "Epoch 496/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2172.1526 - val_loss: 2669.6167\n",
            "Epoch 497/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2169.6301 - val_loss: 2672.1914\n",
            "Epoch 498/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2168.0283 - val_loss: 2699.7412\n",
            "Epoch 499/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2172.8481 - val_loss: 2697.2512\n",
            "Epoch 500/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2159.8733 - val_loss: 2685.7847\n",
            "Epoch 501/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2146.8418 - val_loss: 2679.4971\n",
            "Epoch 502/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 2144.4375 - val_loss: 2669.1208\n",
            "Epoch 503/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2144.6680 - val_loss: 2670.7654\n",
            "Epoch 504/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2144.9043 - val_loss: 2662.0342\n",
            "Epoch 505/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2145.5686 - val_loss: 2660.1658\n",
            "Epoch 506/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2148.6172 - val_loss: 2653.5603\n",
            "Epoch 507/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2152.5437 - val_loss: 2650.3323\n",
            "Epoch 508/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2144.3762 - val_loss: 2649.9602\n",
            "Epoch 509/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2148.0630 - val_loss: 2664.8696\n",
            "Epoch 510/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2138.5410 - val_loss: 2667.9561\n",
            "Epoch 511/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2147.7974 - val_loss: 2665.6970\n",
            "Epoch 512/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2140.9785 - val_loss: 2658.1772\n",
            "Epoch 513/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 2132.9924 - val_loss: 2661.0991\n",
            "Epoch 514/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2131.0515 - val_loss: 2659.3440\n",
            "Epoch 515/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2126.8699 - val_loss: 2655.7922\n",
            "Epoch 516/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2130.6543 - val_loss: 2663.2947\n",
            "Epoch 517/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2136.0471 - val_loss: 2666.9858\n",
            "Epoch 518/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2132.7354 - val_loss: 2671.5066\n",
            "Epoch 519/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2133.2952 - val_loss: 2668.0164\n",
            "Epoch 520/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2129.4985 - val_loss: 2670.7534\n",
            "Epoch 521/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2134.0552 - val_loss: 2668.4846\n",
            "Epoch 522/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2133.6318 - val_loss: 2663.1965\n",
            "Epoch 523/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2123.5901 - val_loss: 2662.5566\n",
            "Epoch 524/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2121.0911 - val_loss: 2663.4233\n",
            "Epoch 525/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 2116.2854 - val_loss: 2667.6135\n",
            "Epoch 526/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2112.7278 - val_loss: 2664.4993\n",
            "Epoch 527/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2115.2227 - val_loss: 2687.4507\n",
            "Epoch 528/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2116.5144 - val_loss: 2686.3733\n",
            "Epoch 529/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2109.0608 - val_loss: 2686.2520\n",
            "Epoch 530/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2112.1370 - val_loss: 2684.7651\n",
            "Epoch 531/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2114.6965 - val_loss: 2669.3547\n",
            "Epoch 532/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2118.3442 - val_loss: 2658.1218\n",
            "Epoch 533/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2113.0422 - val_loss: 2657.1841\n",
            "Epoch 534/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2107.6797 - val_loss: 2669.6360\n",
            "Epoch 535/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2101.9224 - val_loss: 2661.7761\n",
            "Epoch 536/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2118.8484 - val_loss: 2675.2864\n",
            "Epoch 537/1000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2133.1279 - val_loss: 2703.0928\n",
            "Epoch 538/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2135.2310 - val_loss: 2701.4839\n",
            "Epoch 539/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2136.9094 - val_loss: 2682.8096\n",
            "Epoch 540/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2115.9741 - val_loss: 2662.1240\n",
            "Epoch 541/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2099.4023 - val_loss: 2671.5850\n",
            "Epoch 542/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2101.8459 - val_loss: 2678.5054\n",
            "Epoch 543/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2108.2109 - val_loss: 2716.9360\n",
            "Epoch 544/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2099.3557 - val_loss: 2699.0095\n",
            "Epoch 545/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2100.7896 - val_loss: 2698.9448\n",
            "Epoch 546/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 2087.8000 - val_loss: 2698.0815\n",
            "Epoch 547/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 2082.6509 - val_loss: 2708.6924\n",
            "Epoch 548/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2085.5510 - val_loss: 2706.3191\n",
            "Epoch 549/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 2078.8572 - val_loss: 2710.1313\n",
            "Epoch 550/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2080.5703 - val_loss: 2716.4199\n",
            "Epoch 551/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 2078.6179 - val_loss: 2711.7410\n",
            "Epoch 552/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 2074.0049 - val_loss: 2705.4482\n",
            "Epoch 553/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2073.0190 - val_loss: 2699.8501\n",
            "Epoch 554/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2073.4194 - val_loss: 2685.9341\n",
            "Epoch 555/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2079.4595 - val_loss: 2673.9302\n",
            "Epoch 556/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2078.6208 - val_loss: 2670.8508\n",
            "Epoch 557/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 2074.7783 - val_loss: 2666.0891\n",
            "Epoch 558/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 2072.2012 - val_loss: 2670.5225\n",
            "Epoch 559/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 2068.6582 - val_loss: 2665.6724\n",
            "Epoch 560/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 2079.1738 - val_loss: 2667.7710\n",
            "Epoch 561/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2065.6409 - val_loss: 2689.4910\n",
            "Epoch 562/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 2068.7419 - val_loss: 2700.9436\n",
            "Epoch 563/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 2098.5784 - val_loss: 2755.6555\n",
            "Epoch 564/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 2093.2034 - val_loss: 2733.3123\n",
            "Epoch 565/1000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 2079.9922 - val_loss: 2712.8904\n",
            "Epoch 566/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 2063.1660 - val_loss: 2707.5684\n",
            "Epoch 567/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2059.0132 - val_loss: 2702.5916\n",
            "Epoch 568/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 2053.4514 - val_loss: 2694.5513\n",
            "Epoch 569/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 2052.9534 - val_loss: 2691.4878\n",
            "Epoch 570/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 2052.7532 - val_loss: 2688.9209\n",
            "Epoch 571/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2050.3157 - val_loss: 2686.9385\n",
            "Epoch 572/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 2064.2444 - val_loss: 2684.7136\n",
            "Epoch 573/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2057.4778 - val_loss: 2652.8755\n",
            "Epoch 574/1000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2059.4033 - val_loss: 2654.9771\n",
            "Epoch 575/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 2055.3560 - val_loss: 2659.7729\n",
            "Epoch 576/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2051.2678 - val_loss: 2672.5234\n",
            "Epoch 577/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2058.6750 - val_loss: 2686.1772\n",
            "Epoch 578/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2064.6465 - val_loss: 2696.8538\n",
            "Epoch 579/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2069.8835 - val_loss: 2710.1416\n",
            "Epoch 580/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2060.7883 - val_loss: 2703.8560\n",
            "Epoch 581/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 2045.8463 - val_loss: 2703.6475\n",
            "Epoch 582/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2037.6234 - val_loss: 2698.7244\n",
            "Epoch 583/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 2067.4404 - val_loss: 2700.6340\n",
            "Epoch 584/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2057.7112 - val_loss: 2702.7458\n",
            "Epoch 585/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2051.9424 - val_loss: 2697.1121\n",
            "Epoch 586/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2043.4528 - val_loss: 2708.8364\n",
            "Epoch 587/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2036.6420 - val_loss: 2694.1716\n",
            "Epoch 588/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2030.6821 - val_loss: 2698.5186\n",
            "Epoch 589/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2027.1923 - val_loss: 2699.1177\n",
            "Epoch 590/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2022.9304 - val_loss: 2697.3328\n",
            "Epoch 591/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2020.9260 - val_loss: 2704.6873\n",
            "Epoch 592/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2037.0469 - val_loss: 2744.9177\n",
            "Epoch 593/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2041.6825 - val_loss: 2751.0264\n",
            "Epoch 594/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2031.0543 - val_loss: 2743.4888\n",
            "Epoch 595/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2024.9689 - val_loss: 2733.1165\n",
            "Epoch 596/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2017.0990 - val_loss: 2729.4309\n",
            "Epoch 597/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2019.7928 - val_loss: 2720.9680\n",
            "Epoch 598/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2034.4529 - val_loss: 2717.0120\n",
            "Epoch 599/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2035.0397 - val_loss: 2704.1909\n",
            "Epoch 600/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2021.9991 - val_loss: 2707.7258\n",
            "Epoch 601/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2007.0272 - val_loss: 2710.0679\n",
            "Epoch 602/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2014.5900 - val_loss: 2725.2590\n",
            "Epoch 603/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2006.0507 - val_loss: 2718.4006\n",
            "Epoch 604/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2011.3215 - val_loss: 2739.1790\n",
            "Epoch 605/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2063.5415 - val_loss: 2765.5615\n",
            "Epoch 606/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2013.2794 - val_loss: 2737.7361\n",
            "Epoch 607/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2010.1458 - val_loss: 2739.4072\n",
            "Epoch 608/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2014.9625 - val_loss: 2738.1689\n",
            "Epoch 609/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2011.0437 - val_loss: 2745.1465\n",
            "Epoch 610/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1995.2933 - val_loss: 2757.8550\n",
            "Epoch 611/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1999.4596 - val_loss: 2765.1672\n",
            "Epoch 612/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1990.8081 - val_loss: 2742.3269\n",
            "Epoch 613/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1988.2468 - val_loss: 2727.4910\n",
            "Epoch 614/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1988.0610 - val_loss: 2708.6287\n",
            "Epoch 615/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1992.9277 - val_loss: 2710.0833\n",
            "Epoch 616/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1988.3336 - val_loss: 2717.6616\n",
            "Epoch 617/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1981.6390 - val_loss: 2722.4353\n",
            "Epoch 618/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1981.6238 - val_loss: 2723.2991\n",
            "Epoch 619/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1987.4250 - val_loss: 2733.7380\n",
            "Epoch 620/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1994.6558 - val_loss: 2725.6575\n",
            "Epoch 621/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1993.3840 - val_loss: 2717.9790\n",
            "Epoch 622/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2007.6451 - val_loss: 2719.3262\n",
            "Epoch 623/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1983.7020 - val_loss: 2720.1978\n",
            "Epoch 624/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1989.8483 - val_loss: 2727.3462\n",
            "Epoch 625/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1981.9832 - val_loss: 2732.6272\n",
            "Epoch 626/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1981.3704 - val_loss: 2793.7935\n",
            "Epoch 627/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2030.9315 - val_loss: 2825.8220\n",
            "Epoch 628/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2031.1989 - val_loss: 2821.9902\n",
            "Epoch 629/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 2001.0911 - val_loss: 2794.7095\n",
            "Epoch 630/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1978.5510 - val_loss: 2789.7058\n",
            "Epoch 631/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1968.7389 - val_loss: 2774.2012\n",
            "Epoch 632/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1969.4717 - val_loss: 2757.4463\n",
            "Epoch 633/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1986.1451 - val_loss: 2763.3367\n",
            "Epoch 634/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1982.0696 - val_loss: 2747.4600\n",
            "Epoch 635/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1963.1573 - val_loss: 2746.3479\n",
            "Epoch 636/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1958.1848 - val_loss: 2749.3186\n",
            "Epoch 637/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1959.8036 - val_loss: 2785.2021\n",
            "Epoch 638/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1957.7375 - val_loss: 2785.5884\n",
            "Epoch 639/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1953.1321 - val_loss: 2782.0715\n",
            "Epoch 640/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1949.6039 - val_loss: 2778.7051\n",
            "Epoch 641/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1948.7944 - val_loss: 2771.1416\n",
            "Epoch 642/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1956.3789 - val_loss: 2769.6653\n",
            "Epoch 643/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1959.4332 - val_loss: 2766.6628\n",
            "Epoch 644/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1953.2543 - val_loss: 2773.0667\n",
            "Epoch 645/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1953.3020 - val_loss: 2782.9141\n",
            "Epoch 646/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1949.8970 - val_loss: 2773.9626\n",
            "Epoch 647/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1956.3452 - val_loss: 2789.5005\n",
            "Epoch 648/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1954.7096 - val_loss: 2799.1223\n",
            "Epoch 649/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1953.0338 - val_loss: 2815.8721\n",
            "Epoch 650/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1940.7166 - val_loss: 2813.3174\n",
            "Epoch 651/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1935.0233 - val_loss: 2807.1423\n",
            "Epoch 652/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1933.9449 - val_loss: 2800.4800\n",
            "Epoch 653/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1928.7788 - val_loss: 2826.1821\n",
            "Epoch 654/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1930.1357 - val_loss: 2824.4202\n",
            "Epoch 655/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 1926.9980 - val_loss: 2824.4358\n",
            "Epoch 656/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1923.6581 - val_loss: 2828.9912\n",
            "Epoch 657/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1926.9551 - val_loss: 2816.5747\n",
            "Epoch 658/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1926.6592 - val_loss: 2817.5659\n",
            "Epoch 659/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1928.5790 - val_loss: 2814.7354\n",
            "Epoch 660/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1960.9650 - val_loss: 2821.3765\n",
            "Epoch 661/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1953.0184 - val_loss: 2810.3340\n",
            "Epoch 662/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1945.0935 - val_loss: 2805.9033\n",
            "Epoch 663/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1922.1317 - val_loss: 2785.5198\n",
            "Epoch 664/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1919.5558 - val_loss: 2773.7659\n",
            "Epoch 665/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1926.6117 - val_loss: 2755.8215\n",
            "Epoch 666/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1915.6422 - val_loss: 2738.7764\n",
            "Epoch 667/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1927.3633 - val_loss: 2730.9722\n",
            "Epoch 668/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1927.3077 - val_loss: 2731.8240\n",
            "Epoch 669/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1920.8463 - val_loss: 2748.4753\n",
            "Epoch 670/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1930.3877 - val_loss: 2757.3799\n",
            "Epoch 671/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1912.6713 - val_loss: 2769.8154\n",
            "Epoch 672/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1916.4182 - val_loss: 2797.4170\n",
            "Epoch 673/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1911.4351 - val_loss: 2793.6685\n",
            "Epoch 674/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1896.8464 - val_loss: 2790.8291\n",
            "Epoch 675/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1902.2355 - val_loss: 2799.4392\n",
            "Epoch 676/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1893.7350 - val_loss: 2820.9546\n",
            "Epoch 677/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1909.1282 - val_loss: 2830.8613\n",
            "Epoch 678/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1901.5527 - val_loss: 2809.6323\n",
            "Epoch 679/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1901.0195 - val_loss: 2794.9404\n",
            "Epoch 680/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1897.0630 - val_loss: 2806.4934\n",
            "Epoch 681/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1889.0956 - val_loss: 2803.8318\n",
            "Epoch 682/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1882.0018 - val_loss: 2802.2385\n",
            "Epoch 683/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1880.4851 - val_loss: 2803.2666\n",
            "Epoch 684/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1878.7096 - val_loss: 2801.8918\n",
            "Epoch 685/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1886.5359 - val_loss: 2833.8311\n",
            "Epoch 686/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1880.6089 - val_loss: 2830.5635\n",
            "Epoch 687/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1901.0558 - val_loss: 2859.0459\n",
            "Epoch 688/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1903.0510 - val_loss: 2821.5952\n",
            "Epoch 689/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 1884.1223 - val_loss: 2813.5259\n",
            "Epoch 690/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1883.0330 - val_loss: 2809.6096\n",
            "Epoch 691/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 1876.1768 - val_loss: 2819.2266\n",
            "Epoch 692/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1876.2457 - val_loss: 2826.8596\n",
            "Epoch 693/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1883.4006 - val_loss: 2825.7173\n",
            "Epoch 694/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 1878.4756 - val_loss: 2816.3816\n",
            "Epoch 695/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 1872.2234 - val_loss: 2807.8325\n",
            "Epoch 696/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1871.2688 - val_loss: 2809.7983\n",
            "Epoch 697/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1865.0637 - val_loss: 2810.9490\n",
            "Epoch 698/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1865.8401 - val_loss: 2815.3047\n",
            "Epoch 699/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 1870.2292 - val_loss: 2831.3354\n",
            "Epoch 700/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 1867.6820 - val_loss: 2841.6011\n",
            "Epoch 701/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 1863.8079 - val_loss: 2850.4609\n",
            "Epoch 702/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 1857.3711 - val_loss: 2874.0430\n",
            "Epoch 703/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1867.1316 - val_loss: 2875.8813\n",
            "Epoch 704/1000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1860.5051 - val_loss: 2873.4290\n",
            "Epoch 705/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1856.2728 - val_loss: 2897.0603\n",
            "Epoch 706/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 1854.3884 - val_loss: 2889.5989\n",
            "Epoch 707/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1847.4832 - val_loss: 2871.3035\n",
            "Epoch 708/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1848.9504 - val_loss: 2872.6929\n",
            "Epoch 709/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 1850.0841 - val_loss: 2880.9729\n",
            "Epoch 710/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1863.6864 - val_loss: 2906.6116\n",
            "Epoch 711/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1877.9357 - val_loss: 2899.4177\n",
            "Epoch 712/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1856.9175 - val_loss: 2879.5271\n",
            "Epoch 713/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1844.2775 - val_loss: 2853.0198\n",
            "Epoch 714/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1837.4136 - val_loss: 2856.8918\n",
            "Epoch 715/1000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1857.1139 - val_loss: 2843.4724\n",
            "Epoch 716/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 1842.5955 - val_loss: 2836.4910\n",
            "Epoch 717/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 1836.1898 - val_loss: 2837.8984\n",
            "Epoch 718/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 1832.8145 - val_loss: 2855.0227\n",
            "Epoch 719/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1855.1415 - val_loss: 2875.0383\n",
            "Epoch 720/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1874.6250 - val_loss: 2895.9529\n",
            "Epoch 721/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1861.6448 - val_loss: 2900.4233\n",
            "Epoch 722/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1853.7847 - val_loss: 2956.1138\n",
            "Epoch 723/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1860.4564 - val_loss: 2966.0730\n",
            "Epoch 724/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1847.5861 - val_loss: 2945.6755\n",
            "Epoch 725/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1845.7686 - val_loss: 2966.3772\n",
            "Epoch 726/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1841.8566 - val_loss: 2944.6816\n",
            "Epoch 727/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1839.2469 - val_loss: 2923.6140\n",
            "Epoch 728/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1819.8762 - val_loss: 2889.7170\n",
            "Epoch 729/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1823.6144 - val_loss: 2887.5254\n",
            "Epoch 730/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1819.1108 - val_loss: 2882.3894\n",
            "Epoch 731/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1815.7162 - val_loss: 2889.2317\n",
            "Epoch 732/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1809.0118 - val_loss: 2879.2524\n",
            "Epoch 733/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1811.4324 - val_loss: 2887.8091\n",
            "Epoch 734/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1812.5095 - val_loss: 2877.8940\n",
            "Epoch 735/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1810.0801 - val_loss: 2865.0471\n",
            "Epoch 736/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1806.3584 - val_loss: 2856.9902\n",
            "Epoch 737/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1802.5588 - val_loss: 2844.5166\n",
            "Epoch 738/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1805.2574 - val_loss: 2845.9810\n",
            "Epoch 739/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1805.3365 - val_loss: 2844.9543\n",
            "Epoch 740/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1798.5345 - val_loss: 2837.6746\n",
            "Epoch 741/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1803.5803 - val_loss: 2837.4919\n",
            "Epoch 742/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1810.3684 - val_loss: 2826.1797\n",
            "Epoch 743/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1804.1976 - val_loss: 2822.0007\n",
            "Epoch 744/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1800.6498 - val_loss: 2822.1738\n",
            "Epoch 745/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1804.7295 - val_loss: 2852.6973\n",
            "Epoch 746/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1800.1705 - val_loss: 2872.2991\n",
            "Epoch 747/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1788.8467 - val_loss: 2887.7820\n",
            "Epoch 748/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1787.0016 - val_loss: 2910.9551\n",
            "Epoch 749/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1780.6521 - val_loss: 2915.9248\n",
            "Epoch 750/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1791.1620 - val_loss: 2923.4709\n",
            "Epoch 751/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1819.6080 - val_loss: 2929.6885\n",
            "Epoch 752/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1810.4016 - val_loss: 2918.4341\n",
            "Epoch 753/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1791.8148 - val_loss: 2910.3357\n",
            "Epoch 754/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1786.9254 - val_loss: 2908.3301\n",
            "Epoch 755/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1782.1383 - val_loss: 2907.4766\n",
            "Epoch 756/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1780.1659 - val_loss: 2905.3333\n",
            "Epoch 757/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1771.9166 - val_loss: 2911.2390\n",
            "Epoch 758/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1764.1049 - val_loss: 2912.3110\n",
            "Epoch 759/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1765.6342 - val_loss: 2908.7605\n",
            "Epoch 760/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1761.6907 - val_loss: 2904.0627\n",
            "Epoch 761/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1755.7144 - val_loss: 2904.0166\n",
            "Epoch 762/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1756.4653 - val_loss: 2885.4194\n",
            "Epoch 763/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1761.6841 - val_loss: 2878.8164\n",
            "Epoch 764/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1779.7949 - val_loss: 2886.5427\n",
            "Epoch 765/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1804.5559 - val_loss: 2881.6621\n",
            "Epoch 766/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1791.3574 - val_loss: 2891.5640\n",
            "Epoch 767/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1770.7225 - val_loss: 2987.6714\n",
            "Epoch 768/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1847.8494 - val_loss: 3044.3262\n",
            "Epoch 769/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1808.3590 - val_loss: 2979.2332\n",
            "Epoch 770/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1779.1898 - val_loss: 2940.0608\n",
            "Epoch 771/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1752.1019 - val_loss: 2917.9253\n",
            "Epoch 772/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1747.4097 - val_loss: 2902.1658\n",
            "Epoch 773/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1745.7283 - val_loss: 2871.3362\n",
            "Epoch 774/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1754.6094 - val_loss: 2866.9924\n",
            "Epoch 775/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1747.0447 - val_loss: 2862.5544\n",
            "Epoch 776/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1751.4502 - val_loss: 2889.1826\n",
            "Epoch 777/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1769.8342 - val_loss: 2883.6235\n",
            "Epoch 778/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1750.1018 - val_loss: 2869.4285\n",
            "Epoch 779/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1738.6321 - val_loss: 2864.9441\n",
            "Epoch 780/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1731.7548 - val_loss: 2891.9543\n",
            "Epoch 781/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1741.7070 - val_loss: 2958.5447\n",
            "Epoch 782/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1772.7646 - val_loss: 3000.4753\n",
            "Epoch 783/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1748.1432 - val_loss: 2977.2217\n",
            "Epoch 784/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1735.2450 - val_loss: 2985.5596\n",
            "Epoch 785/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1735.8553 - val_loss: 2982.3748\n",
            "Epoch 786/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1729.2308 - val_loss: 2978.5310\n",
            "Epoch 787/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1719.9147 - val_loss: 2972.2883\n",
            "Epoch 788/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1752.3101 - val_loss: 2954.5891\n",
            "Epoch 789/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1744.7214 - val_loss: 2919.0132\n",
            "Epoch 790/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1727.0527 - val_loss: 2917.3435\n",
            "Epoch 791/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1719.3104 - val_loss: 2922.1763\n",
            "Epoch 792/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1721.8896 - val_loss: 2939.6426\n",
            "Epoch 793/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1721.8059 - val_loss: 2930.3076\n",
            "Epoch 794/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1728.1407 - val_loss: 2947.6323\n",
            "Epoch 795/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1734.7328 - val_loss: 2941.4421\n",
            "Epoch 796/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1726.5542 - val_loss: 2916.4846\n",
            "Epoch 797/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1722.5562 - val_loss: 2926.8115\n",
            "Epoch 798/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1716.1615 - val_loss: 2958.9634\n",
            "Epoch 799/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1762.0129 - val_loss: 2966.2554\n",
            "Epoch 800/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1757.4738 - val_loss: 2965.4966\n",
            "Epoch 801/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1718.7222 - val_loss: 2933.3591\n",
            "Epoch 802/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1701.0947 - val_loss: 2931.6089\n",
            "Epoch 803/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1697.3683 - val_loss: 2931.7397\n",
            "Epoch 804/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1693.8695 - val_loss: 2932.7991\n",
            "Epoch 805/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1689.9138 - val_loss: 2927.1165\n",
            "Epoch 806/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1710.0793 - val_loss: 2947.0698\n",
            "Epoch 807/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1716.7418 - val_loss: 2934.8159\n",
            "Epoch 808/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1693.6781 - val_loss: 2915.8655\n",
            "Epoch 809/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1687.4752 - val_loss: 2921.0137\n",
            "Epoch 810/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1719.6576 - val_loss: 2971.9536\n",
            "Epoch 811/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1742.4718 - val_loss: 2957.5898\n",
            "Epoch 812/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1708.9490 - val_loss: 2935.9253\n",
            "Epoch 813/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1692.8899 - val_loss: 2923.0354\n",
            "Epoch 814/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1683.2925 - val_loss: 2910.6467\n",
            "Epoch 815/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1682.3428 - val_loss: 2896.9919\n",
            "Epoch 816/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1698.5990 - val_loss: 2913.1975\n",
            "Epoch 817/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1737.3765 - val_loss: 2945.1892\n",
            "Epoch 818/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1722.3129 - val_loss: 2952.4871\n",
            "Epoch 819/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1693.4839 - val_loss: 2957.6187\n",
            "Epoch 820/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1676.7438 - val_loss: 2972.3103\n",
            "Epoch 821/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1666.1147 - val_loss: 2977.3540\n",
            "Epoch 822/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1666.0283 - val_loss: 2981.6602\n",
            "Epoch 823/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1666.5121 - val_loss: 2991.5105\n",
            "Epoch 824/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1662.6451 - val_loss: 3037.3005\n",
            "Epoch 825/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1669.1525 - val_loss: 3018.2915\n",
            "Epoch 826/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1676.0331 - val_loss: 3000.0344\n",
            "Epoch 827/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1679.9995 - val_loss: 3001.7766\n",
            "Epoch 828/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1679.1783 - val_loss: 3037.3372\n",
            "Epoch 829/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1676.1089 - val_loss: 3050.7622\n",
            "Epoch 830/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1679.4567 - val_loss: 3039.8423\n",
            "Epoch 831/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1674.4303 - val_loss: 3036.8630\n",
            "Epoch 832/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1666.0275 - val_loss: 3020.7866\n",
            "Epoch 833/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1657.5613 - val_loss: 3022.1890\n",
            "Epoch 834/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1655.1964 - val_loss: 3039.1165\n",
            "Epoch 835/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1648.1722 - val_loss: 3033.0310\n",
            "Epoch 836/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1644.6664 - val_loss: 3024.3799\n",
            "Epoch 837/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1642.8196 - val_loss: 3005.9175\n",
            "Epoch 838/1000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1646.2426 - val_loss: 3004.8203\n",
            "Epoch 839/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1640.1266 - val_loss: 3002.8984\n",
            "Epoch 840/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 1636.6339 - val_loss: 3007.7273\n",
            "Epoch 841/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1661.2041 - val_loss: 3037.4529\n",
            "Epoch 842/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1677.3448 - val_loss: 3015.1130\n",
            "Epoch 843/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1656.4520 - val_loss: 2977.5779\n",
            "Epoch 844/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1638.0204 - val_loss: 2957.8992\n",
            "Epoch 845/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 1630.8352 - val_loss: 2968.1177\n",
            "Epoch 846/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1636.4431 - val_loss: 2987.4592\n",
            "Epoch 847/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1628.0624 - val_loss: 3011.0745\n",
            "Epoch 848/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1661.8661 - val_loss: 3010.8721\n",
            "Epoch 849/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1639.0079 - val_loss: 3007.1106\n",
            "Epoch 850/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1626.0066 - val_loss: 3016.7107\n",
            "Epoch 851/1000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1620.5160 - val_loss: 3030.9629\n",
            "Epoch 852/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 1623.0377 - val_loss: 3050.5378\n",
            "Epoch 853/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1627.4490 - val_loss: 3034.0491\n",
            "Epoch 854/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1623.5331 - val_loss: 3011.3484\n",
            "Epoch 855/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1626.3983 - val_loss: 3005.1355\n",
            "Epoch 856/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1619.4988 - val_loss: 3009.9919\n",
            "Epoch 857/1000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1626.3971 - val_loss: 3025.4885\n",
            "Epoch 858/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 1624.3857 - val_loss: 3021.5730\n",
            "Epoch 859/1000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1641.9052 - val_loss: 3041.8806\n",
            "Epoch 860/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 1653.9536 - val_loss: 3049.1541\n",
            "Epoch 861/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 1642.4292 - val_loss: 3082.4536\n",
            "Epoch 862/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1615.1658 - val_loss: 3083.8040\n",
            "Epoch 863/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1614.1805 - val_loss: 3098.6946\n",
            "Epoch 864/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 1616.1158 - val_loss: 3112.7991\n",
            "Epoch 865/1000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1608.4158 - val_loss: 3086.9065\n",
            "Epoch 866/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 1606.3539 - val_loss: 3107.7966\n",
            "Epoch 867/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1631.9497 - val_loss: 3149.5393\n",
            "Epoch 868/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1626.6501 - val_loss: 3138.4392\n",
            "Epoch 869/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 1635.4097 - val_loss: 3158.8772\n",
            "Epoch 870/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1631.0319 - val_loss: 3066.1941\n",
            "Epoch 871/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1594.0453 - val_loss: 3025.0000\n",
            "Epoch 872/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1598.0479 - val_loss: 3016.8669\n",
            "Epoch 873/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1599.8927 - val_loss: 3054.3928\n",
            "Epoch 874/1000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1602.8911 - val_loss: 3060.5105\n",
            "Epoch 875/1000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1592.5695 - val_loss: 3058.1172\n",
            "Epoch 876/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1586.3887 - val_loss: 3048.2021\n",
            "Epoch 877/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1610.9740 - val_loss: 3094.5457\n",
            "Epoch 878/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1625.1976 - val_loss: 3049.1396\n",
            "Epoch 879/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1589.1848 - val_loss: 3015.7805\n",
            "Epoch 880/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1584.3635 - val_loss: 3025.8845\n",
            "Epoch 881/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1581.3625 - val_loss: 3028.9592\n",
            "Epoch 882/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1576.2360 - val_loss: 3030.5002\n",
            "Epoch 883/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1575.5571 - val_loss: 3036.3364\n",
            "Epoch 884/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1570.3403 - val_loss: 3044.0603\n",
            "Epoch 885/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1569.0911 - val_loss: 3055.3743\n",
            "Epoch 886/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1567.8173 - val_loss: 3061.9968\n",
            "Epoch 887/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1564.7589 - val_loss: 3055.4729\n",
            "Epoch 888/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1576.0559 - val_loss: 3072.8452\n",
            "Epoch 889/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1575.7080 - val_loss: 3064.9438\n",
            "Epoch 890/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1570.2028 - val_loss: 3102.1841\n",
            "Epoch 891/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1589.0354 - val_loss: 3114.8665\n",
            "Epoch 892/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1573.1039 - val_loss: 3100.1965\n",
            "Epoch 893/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1560.2625 - val_loss: 3129.3303\n",
            "Epoch 894/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1562.6077 - val_loss: 3123.5095\n",
            "Epoch 895/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1552.3063 - val_loss: 3107.5288\n",
            "Epoch 896/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1556.6074 - val_loss: 3104.5823\n",
            "Epoch 897/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1554.6882 - val_loss: 3108.5098\n",
            "Epoch 898/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1548.4438 - val_loss: 3102.6228\n",
            "Epoch 899/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1543.2700 - val_loss: 3096.2676\n",
            "Epoch 900/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1543.1732 - val_loss: 3091.3672\n",
            "Epoch 901/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1541.7444 - val_loss: 3096.2427\n",
            "Epoch 902/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1556.3394 - val_loss: 3138.4878\n",
            "Epoch 903/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1544.7123 - val_loss: 3105.7026\n",
            "Epoch 904/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1543.3927 - val_loss: 3102.0059\n",
            "Epoch 905/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1538.2657 - val_loss: 3112.7441\n",
            "Epoch 906/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1537.8639 - val_loss: 3110.7927\n",
            "Epoch 907/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1535.2716 - val_loss: 3108.0059\n",
            "Epoch 908/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1532.9789 - val_loss: 3131.3564\n",
            "Epoch 909/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1531.4248 - val_loss: 3113.7346\n",
            "Epoch 910/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1523.2590 - val_loss: 3112.6819\n",
            "Epoch 911/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1523.4426 - val_loss: 3108.2322\n",
            "Epoch 912/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1526.8362 - val_loss: 3124.4519\n",
            "Epoch 913/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1522.3223 - val_loss: 3123.6108\n",
            "Epoch 914/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1540.8545 - val_loss: 3183.8311\n",
            "Epoch 915/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1554.4430 - val_loss: 3168.5295\n",
            "Epoch 916/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1570.5553 - val_loss: 3174.7178\n",
            "Epoch 917/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1569.0134 - val_loss: 3143.4929\n",
            "Epoch 918/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1564.0177 - val_loss: 3116.2485\n",
            "Epoch 919/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 1552.7170 - val_loss: 3099.1104\n",
            "Epoch 920/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1541.5836 - val_loss: 3058.9014\n",
            "Epoch 921/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1533.2859 - val_loss: 3073.9766\n",
            "Epoch 922/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1546.7208 - val_loss: 3085.5730\n",
            "Epoch 923/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1521.5928 - val_loss: 3088.4456\n",
            "Epoch 924/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1509.8373 - val_loss: 3086.4727\n",
            "Epoch 925/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1506.1923 - val_loss: 3099.4578\n",
            "Epoch 926/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1503.0200 - val_loss: 3116.9302\n",
            "Epoch 927/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1504.5519 - val_loss: 3126.9902\n",
            "Epoch 928/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1503.2833 - val_loss: 3125.7654\n",
            "Epoch 929/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1499.9419 - val_loss: 3124.9404\n",
            "Epoch 930/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1494.6094 - val_loss: 3123.6162\n",
            "Epoch 931/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1494.4619 - val_loss: 3133.2422\n",
            "Epoch 932/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1489.2914 - val_loss: 3137.2900\n",
            "Epoch 933/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1489.6445 - val_loss: 3128.9600\n",
            "Epoch 934/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1486.2808 - val_loss: 3117.1211\n",
            "Epoch 935/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1503.1797 - val_loss: 3110.2957\n",
            "Epoch 936/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1518.3639 - val_loss: 3108.0510\n",
            "Epoch 937/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1499.1947 - val_loss: 3120.4966\n",
            "Epoch 938/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1494.3517 - val_loss: 3143.2590\n",
            "Epoch 939/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1490.3018 - val_loss: 3155.8052\n",
            "Epoch 940/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1492.1996 - val_loss: 3159.5151\n",
            "Epoch 941/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1499.7592 - val_loss: 3163.5991\n",
            "Epoch 942/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1492.3857 - val_loss: 3135.6228\n",
            "Epoch 943/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1482.5178 - val_loss: 3135.3870\n",
            "Epoch 944/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1476.2196 - val_loss: 3155.4360\n",
            "Epoch 945/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1504.0117 - val_loss: 3186.9404\n",
            "Epoch 946/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1501.3472 - val_loss: 3162.3948\n",
            "Epoch 947/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1481.1053 - val_loss: 3157.2837\n",
            "Epoch 948/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1476.5333 - val_loss: 3169.2085\n",
            "Epoch 949/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1485.5648 - val_loss: 3152.7219\n",
            "Epoch 950/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1469.3049 - val_loss: 3148.8477\n",
            "Epoch 951/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1469.9802 - val_loss: 3150.6890\n",
            "Epoch 952/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1465.0527 - val_loss: 3152.6448\n",
            "Epoch 953/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1458.3861 - val_loss: 3169.6748\n",
            "Epoch 954/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1455.6936 - val_loss: 3169.0608\n",
            "Epoch 955/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1455.5500 - val_loss: 3187.8154\n",
            "Epoch 956/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1469.2854 - val_loss: 3175.9937\n",
            "Epoch 957/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1456.9967 - val_loss: 3239.1482\n",
            "Epoch 958/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1481.7952 - val_loss: 3246.1265\n",
            "Epoch 959/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1470.1890 - val_loss: 3167.4656\n",
            "Epoch 960/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1466.9312 - val_loss: 3141.5710\n",
            "Epoch 961/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1460.3914 - val_loss: 3147.9646\n",
            "Epoch 962/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1455.1349 - val_loss: 3163.2517\n",
            "Epoch 963/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 1448.6952 - val_loss: 3157.8379\n",
            "Epoch 964/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1441.8004 - val_loss: 3150.1177\n",
            "Epoch 965/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1458.4050 - val_loss: 3166.2429\n",
            "Epoch 966/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1452.5382 - val_loss: 3165.8896\n",
            "Epoch 967/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1442.2683 - val_loss: 3174.5566\n",
            "Epoch 968/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1442.9158 - val_loss: 3229.4150\n",
            "Epoch 969/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1454.0156 - val_loss: 3221.5730\n",
            "Epoch 970/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1450.3223 - val_loss: 3240.7195\n",
            "Epoch 971/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1447.6680 - val_loss: 3221.2461\n",
            "Epoch 972/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1462.6947 - val_loss: 3213.8828\n",
            "Epoch 973/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1444.9934 - val_loss: 3230.6802\n",
            "Epoch 974/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1440.7139 - val_loss: 3218.4341\n",
            "Epoch 975/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1425.7975 - val_loss: 3197.5659\n",
            "Epoch 976/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1429.4852 - val_loss: 3195.1392\n",
            "Epoch 977/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1443.2402 - val_loss: 3197.0793\n",
            "Epoch 978/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1427.9243 - val_loss: 3283.3782\n",
            "Epoch 979/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1438.2463 - val_loss: 3324.8616\n",
            "Epoch 980/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1429.1426 - val_loss: 3267.1909\n",
            "Epoch 981/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1420.7319 - val_loss: 3238.4802\n",
            "Epoch 982/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1437.3457 - val_loss: 3225.4753\n",
            "Epoch 983/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1452.1519 - val_loss: 3213.0767\n",
            "Epoch 984/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1435.1158 - val_loss: 3208.7939\n",
            "Epoch 985/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1431.5311 - val_loss: 3185.6909\n",
            "Epoch 986/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1429.2810 - val_loss: 3200.3315\n",
            "Epoch 987/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1412.6658 - val_loss: 3207.4409\n",
            "Epoch 988/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1404.1986 - val_loss: 3209.4329\n",
            "Epoch 989/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1405.3286 - val_loss: 3208.0200\n",
            "Epoch 990/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1408.8434 - val_loss: 3224.4241\n",
            "Epoch 991/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1402.3059 - val_loss: 3244.5383\n",
            "Epoch 992/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 1400.4252 - val_loss: 3243.8887\n",
            "Epoch 993/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1407.3279 - val_loss: 3275.9666\n",
            "Epoch 994/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 1410.6311 - val_loss: 3284.3904\n",
            "Epoch 995/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 1401.3685 - val_loss: 3280.1572\n",
            "Epoch 996/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 1390.1433 - val_loss: 3281.2083\n",
            "Epoch 997/1000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1386.6216 - val_loss: 3271.7991\n",
            "Epoch 998/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1390.5609 - val_loss: 3293.1299\n",
            "Epoch 999/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1389.6901 - val_loss: 3293.3726\n",
            "Epoch 1000/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 1407.0211 - val_loss: 3320.4390\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_mlp = model_mlp.evaluate(x_test_scaled, y_test)\n",
        "print('mean squared error:', loss_mlp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62lzoAdqNV4k",
        "outputId": "a13e9820-45e3-4466-956a-ce12ed77fbed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 6ms/step - loss: 3320.4390\n",
            "mean squared error: 3320.43896484375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plot training history\n",
        "\n",
        "plt.plot(history_mlp.history['loss'], label='training Loss')\n",
        "plt.plot(history_mlp.history['val_loss'], label='testing Loss')\n",
        "plt.title('MLP model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epochs')\n",
        "plt.legend();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "iHy093ZSPE-m",
        "outputId": "527f4b4c-6b51-4472-cf60-cb3cb49eabd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6c2nkKeYPcB7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}